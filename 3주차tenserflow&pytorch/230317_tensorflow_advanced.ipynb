{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwlPAA8ZJUsr"
      },
      "source": [
        "Copyright (C) 2019-2023 Software Platform Lab, Seoul National University\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); \n",
        "\n",
        "you may not use this file except in compliance with the License. \n",
        "\n",
        "You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 \n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software \n",
        "\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS, \n",
        "\n",
        "\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n",
        "\n",
        "\n",
        "See the License for the specific language governing permissions and\n",
        "\n",
        "\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO8dQBJs5Yxh"
      },
      "source": [
        "## Defining a model in TensorFlow \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV9KmwLR_wBQ"
      },
      "source": [
        "In TensorFlow, various libraries regarding the model definition are provided under `tf.keras`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqWzzFUO79nx"
      },
      "source": [
        "### Model Subclassing\n",
        "We can build a fully-customizable model by subclassing [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model) and defining your own forward pass. Layers are created in the `__init__` method, provided by the [tf.keras.layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers)  and they are set as attributes of the class instance. The forward pass is defined in the `call` method. You can access model variables by `model.trainable_variables`.\n",
        "\n",
        "Below is an example of a linear regression model to be defined as a subclass of `tf.keras.Model`, and then be trained using loss function, gradient function and optimizer provided in [tf.keras.optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers). Useful loss functions are also provided in [tf.keras.losses](https://www.tensorflow.org/api_docs/python/tf/keras/losses). We will cover these in more detail as we go on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu-X05yCDq9V"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRHEy317_-s0"
      },
      "source": [
        "NUM_EXAMPLES = 2000\n",
        "toy_inputs = tf.random.normal([NUM_EXAMPLES, 1])\n",
        "noise = tf.random.normal([NUM_EXAMPLES, 1])\n",
        "toy_outputs = toy_inputs * 2 - 1 + noise * 1/4#약간의 noise를 줌."
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy1x6VF-_-s1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2c02250-f78f-4879-a600-cb9e64594f4c"
      },
      "source": [
        "class ToyModel(tf.keras.Model):\n",
        "    def __init__(self):#상속을 받은 constructor\n",
        "        \"\"\"Define layers\"\"\"\n",
        "        super(ToyModel, self).__init__()\n",
        "        self.dense = tf.keras.layers.Dense(units=1)#히든레이어의 unit 개수를 지정\n",
        "\n",
        "    def call(self, input):\n",
        "        \"\"\"Define forward pass.\"\"\"\n",
        "        result = self.dense(input)#input이 들어오면 result 리턴 전에 dense layer에 input을 넣을 것.\n",
        "        return result\n",
        "\n",
        "\n",
        "# The loss function to be optimized (MSE loss)\n",
        "def loss(model, inputs, targets):\n",
        "    error = model(inputs) - targets\n",
        "    return tf.reduce_mean(tf.square(error))#mean: 무시해도 좋다.\n",
        "\n",
        "optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.01)#로스를 최대한 줄이기 위한 optimizer\n",
        "\n",
        "model = ToyModel()\n",
        "print(\"Initial loss: {:.3f}\".format(loss(model, toy_inputs, toy_outputs)))\n",
        "print(\"Trainable variables:\")\n",
        "for var in model.trainable_variables:\n",
        "  print(\"\\t\", var.name, \": \", var.numpy())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial loss: 8.505\n",
            "Trainable variables:\n",
            "\t toy_model/dense_3/kernel:0 :  [[-0.6849946]]\n",
            "\t toy_model/dense_3/bias:0 :  [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ3w_EmG7shn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80222ded-ab38-4e7d-8a86-6999a54cbbd7"
      },
      "source": [
        "# Training loop\n",
        "for i in range(300):\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss_value = loss(model, toy_inputs, toy_outputs)\n",
        "    grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    if i % 20 == 0:\n",
        "        print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model, toy_inputs, toy_outputs)))\n",
        "\n",
        "print(\"Final loss: {:.3f}\".format(loss(model, toy_inputs, toy_outputs)))\n",
        "print(\"Trainable variables:\")\n",
        "for var in model.trainable_variables:\n",
        "  print(\"\\t\", var.name, \": \", var.numpy())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at step 000: 8.161\n",
            "Loss at step 020: 3.584\n",
            "Loss at step 040: 1.594\n",
            "Loss at step 060: 0.729\n",
            "Loss at step 080: 0.352\n",
            "Loss at step 100: 0.188\n",
            "Loss at step 120: 0.117\n",
            "Loss at step 140: 0.085\n",
            "Loss at step 160: 0.072\n",
            "Loss at step 180: 0.066\n",
            "Loss at step 200: 0.063\n",
            "Loss at step 220: 0.062\n",
            "Loss at step 240: 0.062\n",
            "Loss at step 260: 0.062\n",
            "Loss at step 280: 0.061\n",
            "Final loss: 0.061\n",
            "Trainable variables:\n",
            "\t toy_model/dense_3/kernel:0 :  [[1.9960607]]\n",
            "\t toy_model/dense_3/bias:0 :  [-0.98994845]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8MEnHhAvskB"
      },
      "source": [
        "It's not required to set an input shape for the `tf.keras.Model` class since the parameters are set the first time input is passed to the layer.\n",
        "\n",
        "tf.keras.layers classes create and contain their own model variables that are tied to the lifetime of their layer objects. To share layer variables, share their objects.\n",
        "\n",
        "Below examples shows a new model that relies on the previous toy model. We are going to employ an additional bias to fit a slightly different data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFF5jQ___-s7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f60182e-f084-47ef-f11f-0bc31d35f085"
      },
      "source": [
        "toy_outputs_2 = toy_outputs + 3\n",
        "\n",
        "class ToyModel2(tf.keras.Model):\n",
        "    def __init__(self, toy_model):\n",
        "        \"\"\"Define layers\"\"\"\n",
        "        super(ToyModel2, self).__init__()\n",
        "        self.toy_model = toy_model\n",
        "        self.b = tf.Variable(0., name='another_bias')\n",
        "\n",
        "    def call(self, input):\n",
        "        \"\"\"Define forward pass.\"\"\"\n",
        "        result = self.toy_model(input)        \n",
        "        return result + self.b\n",
        "\n",
        "\n",
        "model2 = ToyModel2(model)\n",
        "print(\"Initial loss: {:.3f}\".format(loss(model2, toy_inputs, toy_outputs_2)))\n",
        "print(\"Trainable variables:\")\n",
        "for var in model2.trainable_variables:\n",
        "  print(\"\\t\", var.name, \": \", var.numpy())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial loss: 9.045\n",
            "Trainable variables:\n",
            "\t toy_model/dense_3/kernel:0 :  [[1.9960607]]\n",
            "\t toy_model/dense_3/bias:0 :  [-0.98994845]\n",
            "\t another_bias:0 :  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZf0cTk7_-s9"
      },
      "source": [
        "We are only optimizing the additional bias. The weight and bias of toy_model_1 does not change."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhNlE5mTw7bX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9406d92-bd06-4336-970d-131593b09501"
      },
      "source": [
        "# Training loop\n",
        "for i in range(300):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model2, toy_inputs, toy_outputs_2)\n",
        "    grads = tape.gradient(loss_value, [model2.b]) # gradient w.r.t. `model2.b`, not `model2.trainable_variables`\n",
        "    optimizer.apply_gradients(zip(grads, [model2.b])) # optimize only `model2.b`\n",
        "    if i % 20 == 0:\n",
        "        print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model2, toy_inputs, toy_outputs_2)))\n",
        "\n",
        "print(\"Final loss: {:.3f}\".format(loss(model2, toy_inputs, toy_outputs_2)))\n",
        "print(\"Trainable variables:\")\n",
        "for var in model2.trainable_variables:\n",
        "  print(\"\\t\", var.name, \": \", var.numpy())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at step 000: 8.689\n",
            "Loss at step 020: 3.907\n",
            "Loss at step 040: 1.775\n",
            "Loss at step 060: 0.825\n",
            "Loss at step 080: 0.402\n",
            "Loss at step 100: 0.213\n",
            "Loss at step 120: 0.129\n",
            "Loss at step 140: 0.092\n",
            "Loss at step 160: 0.075\n",
            "Loss at step 180: 0.067\n",
            "Loss at step 200: 0.064\n",
            "Loss at step 220: 0.063\n",
            "Loss at step 240: 0.062\n",
            "Loss at step 260: 0.062\n",
            "Loss at step 280: 0.062\n",
            "Final loss: 0.061\n",
            "Trainable variables:\n",
            "\t toy_model/dense_3/kernel:0 :  [[1.9960607]]\n",
            "\t toy_model/dense_3/bias:0 :  [-0.98994845]\n",
            "\t another_bias:0 :  2.9902055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjAodT-v_-r7"
      },
      "source": [
        "## Convolutional Neural Networks\n",
        "Build simple CNN in TensorFlow.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LQHVwI1g_PF"
      },
      "source": [
        "### Preparing MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LydTwAzMhHw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "410c3f19-bcbd-4b5f-b2f1-658fa10a4456"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Download the mnist dataset using keras\n",
        "data_train, data_test = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Parse images and labels\n",
        "(train_images, train_labels) = data_train\n",
        "(test_images, test_labels) = data_test\n",
        "\n",
        "# Numpy reshape & type casting\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_labels = train_labels.astype('int64')\n",
        "test_labels = test_labels.astype('int64')\n",
        "\n",
        "\n",
        "# Normalizing the images to the range of [0., 1.]\n",
        "train_images /= 255.#0부터 시작하니까 255.\n",
        "test_images /= 255.\n",
        "\n",
        "print(train_images.shape, train_labels.shape)\n",
        "print(test_images.shape, test_labels.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "(60000, 28, 28, 1) (60000,)\n",
            "(10000, 28, 28, 1) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ5XuFPCBOZR"
      },
      "source": [
        "### Define the CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_USTku5_-r8"
      },
      "source": [
        "from tensorflow.keras import Model\n",
        "# Construct a tf.keras.model using tf.keras\n",
        "class MyCNN(Model):\n",
        "  def __init__(self):\n",
        "    super(MyCNN, self).__init__()\n",
        "    self.conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='valid')\n",
        "    self.conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='valid')\n",
        "    self.conv3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='valid')\n",
        "    self.maxpool = tf.keras.layers.MaxPooling2D((2, 2))#no stride, 아마도 1이 된다??\n",
        "    self.flatten = tf.keras.layers.Flatten()#3d 4d 형태의 차원을 1차원화.\n",
        "    self.dense1 = tf.keras.layers.Dense(256, activation='relu')\n",
        "    self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.flatten(x)\n",
        "    x = self.dense1(x)\n",
        "    x = self.dense2(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "# Create model\n",
        "model = MyCNN()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk4Cg8gRpWH_"
      },
      "source": [
        "### Setting up training\n",
        "After the model is constructed, we specify optimizer and loss function. We can also monitor training using metrics:\n",
        "* `optimizer`: This field specifies which optimizer to use. We can pass an optimizer instance (e.g., `tf.keras.optimizers.Adam`, `tf.keras.optimizers.RMSProp`), which are defined in  `tf.train` module.\n",
        "* `loss`: The function to minimize during optimization. Common choices include `mean square error (mse)`, `[categorical|binary]_crossentropy`. Loss functions are specified by name or by passing a callable object from the `tf.keras.losses` module.\n",
        "* `metrics`: Used to monitor training. We can put string names or callables defined in `tf.keras.metrics` module (e.g. `'accuracy'`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cBrLLCDpq2a"
      },
      "source": [
        "# Choose loss function and optimizer for training\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()#추천\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# Metrics to measure loss and accuracy of the model\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXKIy_UECa7P"
      },
      "source": [
        "### Train and Test functions using `tf.function`\n",
        "By annotating a train function with `tf.function`, TensorFlow internally creates a graph so that it can benefit from graph-based execution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUZYje1bC1xB"
      },
      "source": [
        "# Define function for training\n",
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images, training=True)\n",
        "    loss = loss_fn(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)\n",
        "\n",
        "# Define function for testing\n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  predictions = model(images, training=False)\n",
        "  loss = loss_fn(labels, predictions)\n",
        "\n",
        "  test_loss(loss)\n",
        "  test_accuracy(labels, predictions)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDilJK1dC4f_"
      },
      "source": [
        "### Prepare the dataset and start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "797JZG-zDBFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb5d60e8-bbc0-492e-cef3-5727188cbda2"
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "# Prepare the dataset using tf.data\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_ds = train_ds.shuffle(10000)\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "test_ds = test_ds.batch(batch_size)\n",
        "\n",
        "\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Reset the metrics at each epoch\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "\n",
        "    for images, labels in train_ds:\n",
        "      train_step(images, labels)\n",
        "\n",
        "    for images, labels in test_ds:\n",
        "      test_step(images, labels)\n",
        "\n",
        "    print('Epoch: %02d' % (epoch + 1),\n",
        "          'Loss = {:2.4f}'.format(train_loss.result()),\n",
        "          'Train accuracy = {:2.4f}'.format(train_accuracy.result()),\n",
        "          'Test loss = {:2.4f}'.format(test_loss.result()),\n",
        "          'Test accuracy = {:2.4f}'.format(test_accuracy.result()))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 Loss = 0.2862 Train accuracy = 0.9117 Test loss = 0.0883 Test accuracy = 0.9720\n",
            "Epoch: 02 Loss = 0.0846 Train accuracy = 0.9739 Test loss = 0.0574 Test accuracy = 0.9826\n",
            "Epoch: 03 Loss = 0.0609 Train accuracy = 0.9811 Test loss = 0.0546 Test accuracy = 0.9828\n",
            "Epoch: 04 Loss = 0.0470 Train accuracy = 0.9859 Test loss = 0.0582 Test accuracy = 0.9835\n",
            "Epoch: 05 Loss = 0.0379 Train accuracy = 0.9886 Test loss = 0.0549 Test accuracy = 0.9832\n",
            "Epoch: 06 Loss = 0.0319 Train accuracy = 0.9900 Test loss = 0.0463 Test accuracy = 0.9856\n",
            "Epoch: 07 Loss = 0.0281 Train accuracy = 0.9911 Test loss = 0.0569 Test accuracy = 0.9828\n",
            "Epoch: 08 Loss = 0.0227 Train accuracy = 0.9924 Test loss = 0.0449 Test accuracy = 0.9880\n",
            "Epoch: 09 Loss = 0.0191 Train accuracy = 0.9939 Test loss = 0.0378 Test accuracy = 0.9898\n",
            "Epoch: 10 Loss = 0.0167 Train accuracy = 0.9945 Test loss = 0.0428 Test accuracy = 0.9872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7f9KSx3D9kF"
      },
      "source": [
        "## More simplified process using Keras API\n",
        "Keras API provides much simpler version to define a model and train a model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvCIHyMGEPEo"
      },
      "source": [
        "### Defining a model\n",
        "Let's take a look how we can define a model using Keras API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8PUmEq5rO44"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "# Let's build a stack of *sequential* layers, which is\n",
        "# the most common form of neural network graphs.\n",
        "model = models.Sequential()\n",
        "\n",
        "# Adds a reshaping layer that transforms (28, 28, 1) to (784,)\n",
        "model.add(layers.Reshape((784,), input_shape=(28, 28, 1)))\n",
        "\n",
        "# Adds a dense layer with 128 units to the model\n",
        "model.add(layers.Dense(units=128, activation='relu'))\n",
        "\n",
        "# Adds another layer, which has L2 regularization applied to the kernel matrix\n",
        "model.add(layers.Dense(units=64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "\n",
        "# Adds a dense layer with 10 output units\n",
        "model.add(layers.Dense(units=10, activation='linear'))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJq7I5kOc1H-"
      },
      "source": [
        "### Setting up training\n",
        "After the model is constructed, `compile` method configures how to learn the model, by specifying optimizer, loss function and metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocskyx96c0UY"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSo7qrwZlOrl"
      },
      "source": [
        "### Training a model\n",
        "We can train the model using the `fit` method and then the model is \"fit\" to the training data. We can specify the training data to use (`images_train` and `labels_train`), how many epochs we will run (`epochs`), and how many items to be processed in a batch (`batch_size`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPOV-4VXk53s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "171de286-740f-4ef4-c7f5-1a7ad8f40acb"
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=10, batch_size=128)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469/469 [==============================] - 4s 5ms/step - loss: 0.0157 - accuracy: 0.9949\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0133 - accuracy: 0.9955\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0115 - accuracy: 0.9963\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0092 - accuracy: 0.9967\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0074 - accuracy: 0.9976\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0075 - accuracy: 0.9975\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0061 - accuracy: 0.9983\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0058 - accuracy: 0.9984\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0057 - accuracy: 0.9982\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0043 - accuracy: 0.9984\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff182458fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymPOEP3BlivE"
      },
      "source": [
        "### Evaluating the model\n",
        "Finally, we evaluate the trained model using test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV5w-V99l0Di",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29b01d12-d088-42de-9dee-fb26fc59a13d"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 0.0692 - accuracy: 0.9889 - 923ms/epoch - 3ms/step\n",
            "Test accuracy: 0.9889000058174133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4ORwtammNNb"
      },
      "source": [
        "### **Quiz**\n",
        "First, define a multi-layer model using Keras API following the CNN model defined in the beginning.\n",
        "\n",
        "The model should contain at least 3 convolutional layers, 2 max pooling layers, and 1 dense layer.\n",
        "\n",
        "The test accuracy after training should be higher than 99%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhKpYAgszdkI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90582e08-3330-41a2-89dc-44ba43dad9af"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "############# Write here. ############# contain at least 3 convolutional layers, 2 max pooling layers, and 1 dense layer.\n",
        "# the most common form of neural network graphs.\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
        "                  padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "    layers.Conv2D(64, kernel_size=(2, 2), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Conv2D(64, kernel_size=(2, 2), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Dropout(0.25),#overfitting을 막기 위함\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(1000, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.summary()#모델의 layer을 보여줍니다.\n",
        "\n",
        "####################################### test accuracy after training should be higher than 99%."
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 32)        832       \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 14, 14, 64)        8256      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 7, 7, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 7, 7, 64)          16448     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 3, 3, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 3, 3, 64)          0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1000)              577000    \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 10)                10010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 612,546\n",
            "Trainable params: 612,546\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmnL8eeL613b"
      },
      "source": [
        "Using the model and `(train_images, train_labels)` above, let's train the model using the following configuration:\n",
        "* optimizer: `tf.keras.optimizers.Adam`\n",
        "* learning rate: 0.001\n",
        "* loss: `SparseCategoricalCrossentropy`\n",
        "* metrics: `accuracy`\n",
        "* batch size: 128\n",
        "* epochs: 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0tNzWLWz0bj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "479c07e3-615e-4169-f9a2-1fab3637e470"
      },
      "source": [
        "############# Write here. #############\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=128)\n",
        "#######################################\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 5s 7ms/step - loss: 0.2290 - accuracy: 0.9279\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0648 - accuracy: 0.9799\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0485 - accuracy: 0.9842\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0385 - accuracy: 0.9878\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0331 - accuracy: 0.9892\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0282 - accuracy: 0.9909\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0254 - accuracy: 0.9918\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0217 - accuracy: 0.9928\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0209 - accuracy: 0.9932\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0180 - accuracy: 0.9944\n",
            "313/313 - 2s - loss: 0.0246 - accuracy: 0.9919 - 2s/epoch - 5ms/step\n",
            "Test accuracy: 0.9919000267982483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOowIsLDs7J_"
      },
      "source": [
        "## Wrap-up\n",
        "\n",
        "So far, we have learned how we can define and train models in TensorFlow. For more information you can refer to [guides in TensorFlow official website](https://www.tensorflow.org/guide) and many other blog posts."
      ]
    }
  ]
}