{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMxaw1c2c0Ti"
      },
      "source": [
        "# 2023 IAB Challenge - Text Classification\n",
        "\n",
        "\n",
        "## About This Challenge\n",
        "\n",
        "This is the in-class challenge held in Seoul National University.\n",
        "\n",
        "We will use **techniques learned in class** to classify the given dialog.\n",
        "\n",
        "사람과 챗봇이 주고 받는 대화가 주어지는데, 사람이 마지막으로 질문의 주체가 속한 카테고리를 예측하는 Text classification 모델을 만들어야합니다.\n",
        "\n",
        "주어진 데이터의 전처리 과정, 모델 설계 및 학습을 진행합니다.\n",
        "\n",
        " **<span style=\"color:red\">단, 이미 학습된 모델을 사용할 수 없습니다. (pre-trained language model 사용 금지)</span>**\n",
        "\n",
        "\n",
        "아래 스켈레톤 코드를 기반으로 코드를 작성하셔도 되고, 새로 작성하셔도 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOYOwU2wZK2z"
      },
      "source": [
        "## **Kaggle 제출 ID: _______**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0LMr94JkmVS"
      },
      "source": [
        "## 제출 목록 및 기한\n",
        "* output.csv: **오늘 17:30 까지** kaggle inclass 에 제출\n",
        "* 본 노트북: **오늘 17:30 까지** ETL 에 제출\n",
        "* 코드에 대한 보고서: **내일 정오(6/17 11:59 AM)까지** A4 한장 내로 작성하여 ETL 에 제출\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IdN2xUA_t3h"
      },
      "source": [
        "## 사전 준비\n",
        "* 데이터 다운로드\n",
        "* 라이브러리 import, install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuHtK7uKc4wx",
        "collapsed": true
      },
      "source": [
        "# 데이터 다운로드\n",
        "# 아래 코드 실행시 iabc_challenge_20 폴더가 보여야함\n",
        "!git clone https://github.com/younhyungchae/iab_challenge_23.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6nCT3GPzwZV"
      },
      "source": [
        "# 필요한 라이브러리 import, install\n",
        "!pip install torchtext==0.6.0\n",
        "\n",
        "import os\n",
        "import json\n",
        "import spacy\n",
        "import spacy.cli\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from torchtext import data, datasets\n",
        "from torchtext.vocab import Vocab\n",
        "from collections import Counter\n",
        "\n",
        "spacy.cli.download(\"en_core_web_sm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC5UC1LR_6NE"
      },
      "source": [
        "# Reproduce 를 하기 위한 셀입니다. 지우지마세요.\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpNYNKgAc0Tp"
      },
      "source": [
        "## Part 1. Loading Data\n",
        "\n",
        "이번 챌린지에서 사용하는 데이터를 로드하고, 데이터의 형태를 확인하는 파트입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVvzOAPXc0Tq"
      },
      "source": [
        "DATA_DIR = './iab_challenge_23/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr2waavIc0Tr"
      },
      "source": [
        "# 데이터 로드\n",
        "def load_data(data_dir, split):\n",
        "    x = json.load(open(os.path.join(data_dir, split, \"logs.json\"), 'r'))\n",
        "    if split != \"test\":\n",
        "        y = json.load(open(os.path.join(data_dir, split, \"labels.json\"), 'r'))\n",
        "    else: y = []\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vTwZLrsc0Tr"
      },
      "source": [
        "X_train, y_train = load_data(DATA_DIR, \"train\")\n",
        "X_val, y_val = load_data(DATA_DIR, \"val\")\n",
        "X_test, _ = load_data(DATA_DIR, \"test\")\n",
        "\n",
        "print(\"Number of training data:\", len(X_train))\n",
        "print(\"Number of validation data:\", len(X_val))\n",
        "print(\"Number of test data:\", len(X_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BTqZWejc0Tt"
      },
      "source": [
        "### Raw data exploration\n",
        "* X_train, X_test: User, System 두 speaker 가 주고 받는 대화. json 형태로 구성되어있음.\n",
        "* y_train, y_test: 마지막 질문이 묻고 있는 대상 (hotel, restaurant, train, taxi)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVJqhOXoc0Tt"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ytq1fa6mc0Tu"
      },
      "source": [
        "print(\"Unique labels:\", set([y for y in y_train]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ywnl2N-zc0Tu"
      },
      "source": [
        "## Part 2. Preprocess Data & Build Vocab\n",
        "\n",
        "1. 대화 컨텍스트를 하나의 시퀀스로 변환\n",
        "2. 라벨을 1-4 class 로 변환\n",
        "3. torchtext 의 Field 정의하여 vocab 생성\n",
        "4. Iterator 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF29P_dic0Tv"
      },
      "source": [
        "### 2-1. 대화 컨텍스트를 하나의 시퀀스로 변환\n",
        "* X_train\\[0\\]을 보면 dictionary 형태로 각 utterance 가 보여지는데 하나의 문장으로 변환해야함.\n",
        "* utterance 를 이어붙여 하나의 문장으로 만 때, utterance 개수를 조절하거나, 앞->뒤 혹은 뒤->앞 으로 수정 가능함.\n",
        "* 또한 화자를 special token (e.g.\\<U>, \\<S>) 을 정의하여 추가로 표시해줄 수도 있음. 이처럼 해당 태스크만을 위해 사용되는 토큰을 special token 이라고 함\n",
        "* 아래 예시로 제공된 process_data 는 마지막 utterance 만 추출하도록 작성되어있음\n",
        "* 제공된 process_data 를 수정하거나 새로 함수를 정의하여 전처리하고, **전처리 방법에 대해 보고서에서 설명해주세요.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvUv-06uc0Tv"
      },
      "source": [
        "###########################################################\n",
        "## 대화 텍스트를 하나의 시퀀스로 전처리하는 함수를 작성하세요.         ##\n",
        "## 예시로 제공한 함수를 그대로 사용해도 되고, 수정하여 사용해도 됩니다.  ##\n",
        "###########################################################\n",
        "\n",
        "special_token = {\"U\": \"<U>\", \"S\": \"<S>\"}\n",
        "\n",
        "def process_data(X, window_size=1, use_speaker_tag=False):\n",
        "    # Arguments 설명\n",
        "    # window_size: 뒤에서부터 추출하려는 utterance 개수 조절하는 인자.\n",
        "    #              Default 는 마지막 문장만 추출됨\n",
        "    # user_speaker_tag: True 일 경우 special token 을 사용하여 화자를 표시.\n",
        "    #                   위에 정의된 special_token 을 사용할 수도 있고 따로 정의해도 됨.\n",
        "\n",
        "    X_output = []\n",
        "    if not use_speaker_tag:\n",
        "        for log in X:\n",
        "            input_seq = \" \".join([utt[\"text\"] for utt in log[-window_size:]])\n",
        "            X_output.append(input_seq)\n",
        "    return X_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNMJcjJGfSuo"
      },
      "source": [
        "print(\"변경 전\")\n",
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCWkJL0Ec0Tv"
      },
      "source": [
        "###########################################################\n",
        "## 위에서 정의한 process_data 혹은 본인이 정의한 함수를 사용하여    ##\n",
        "## 대화 텍스트를 하나의 시퀀스로 전처리하세요.                     ##\n",
        "###########################################################\n",
        "\n",
        "X_train = process_data(X_train)\n",
        "X_val = process_data(X_val)\n",
        "X_test = process_data(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vorJ4BHUc0Tw"
      },
      "source": [
        "print(\"변경 후\")\n",
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEv4QLo9c0Tw"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ5riSobc0Tw"
      },
      "source": [
        "### 2-2. 라벨을 1-4 로 변환\n",
        "\n",
        "각 라벨을 1-4 로 매핑하는 dictionary 는 테스트 데이터의 output.csv 를 만들 때 사용됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_xxarS1c0Tw"
      },
      "source": [
        "LABEL_MAPPING = {\n",
        "    'hotel': 0,\n",
        "    'restaurant': 1,\n",
        "    'taxi': 2,\n",
        "    'train': 3,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPDjoxV0c0Tx"
      },
      "source": [
        "print(\"변경 전:\", y_train[:5])\n",
        "y_train = [LABEL_MAPPING[y] for y in y_train]\n",
        "y_val = [LABEL_MAPPING[y] for y in y_val]\n",
        "print(\"변경 후:\", y_train[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEJuYa0Z_3rv"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrnIuoe7c0Tx"
      },
      "source": [
        "### 2-3. Field 로 정의하여 Vocab 만들기\n",
        "* torchtext 의 TabularDataset class 사용합니다.\n",
        "* 이를 위하여 train_data, test_data 를 csv 형태로 저장한 후, TabularDataset 을 사용하여 torchtext Dataset 객체로 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stlJPACpc0Ty"
      },
      "source": [
        "import pandas as pd\n",
        "from torchtext.data import TabularDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJN9UC16c0Ty"
      },
      "source": [
        "import pandas as pd\n",
        "train_data = pd.DataFrame([[x, y] for x, y in zip(X_train, y_train)], columns=[\"text\", \"label\"])\n",
        "val_data = pd.DataFrame([[x, y] for x, y in zip(X_val, y_val)], columns=[\"text\", \"label\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfGx9u24c0Ty"
      },
      "source": [
        "# csv 형태로 변환\n",
        "print(\"Train data\")\n",
        "display(train_data.head())\n",
        "print(\"\\nVal data\")\n",
        "display(val_data.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4VO81jAc0Ty"
      },
      "source": [
        "# csv 로 저장\n",
        "train_data.to_csv('./iab_challenge_23/train.csv', index=False)\n",
        "val_data.to_csv('./iab_challenge_23/val.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x-M6dCIc0Tz"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwGKgDNLc0Tz"
      },
      "source": [
        "# Field 정의\n",
        "TEXT = data.Field(use_vocab=True, include_lengths=True)\n",
        "LABEL = data.LabelField(is_target=True, use_vocab=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AivzLVh2c0Tz"
      },
      "source": [
        "train_data, val_data = TabularDataset.splits(\n",
        "        path='./iab_challenge_23/', train='train.csv', test='val.csv', format='csv',\n",
        "        fields=[('text', TEXT), ('label', LABEL)], skip_header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZNEx4Xjc0Tz"
      },
      "source": [
        "print('훈련 샘플의 개수 : {}'.format(len(train_data)))\n",
        "print('테스트 샘플의 개수 : {}'.format(len(val_data)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv659XJCfGHU"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnk9y0TcAni_"
      },
      "source": [
        "* Special token 을 사용했을 경우 vocab 에 해당 토큰을 추가해야합니다.\n",
        "* 참고: https://torchtext.readthedocs.io/en/latest/vocab.html#module-torchtext.vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oWfJdWIc0T0"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "TEXT.build_vocab(train_data,\n",
        "                 specials=[],\n",
        "                 max_size = MAX_VOCAB_SIZE,\n",
        "                 vectors = \"glove.6B.100d\",\n",
        "                 unk_init = torch.Tensor.normal_\n",
        "                 )\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5waYV2wtc0T0"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HbjlxkFc0T0"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPUI-K6Gc0T1"
      },
      "source": [
        "### 2-4. Prepare BucketIterator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfljfV_3c0T1"
      },
      "source": [
        "- GPU 사용을 위한 Cuda 설정\n",
        "- Colab 페이지 상단 메뉴>수정>노트설정에서 GPU 사용 설정이 선행되어야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeGmBCKbc0T1"
      },
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veBnTtCiBAEr"
      },
      "source": [
        "* batch 에 속한 인스턴스의 input 길이가 다르기 때문에 iterator 에서 \\<pad> 를 뒤에 붙여서 batch 내 모든 인스턴스의 input 길이가 동일하도록 만듭니다.\n",
        "* \\<pad> 가 적게 들어가도록 sort을 해야하는데 이에 대한 처리를\n",
        "해야합니다.\n",
        "* 참고: https://torchtext.readthedocs.io/en/latest/data.html#bucketiterator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoXErMW1c0T1"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "train_iterator, val_iterator = data.BucketIterator.splits(\n",
        "    ########################################################################\n",
        "    ## BucketIterator 를 사용하여 train_iterator, val_iterator 를 정의해주세요. ##\n",
        "    ## <pad> 를 적게 사용하기 위하여 sorting 을 해야하는 점을 참고하시기 바랍니다.      ##\n",
        "    #######################################################################\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ4SjvdEc0T2"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xGxhpLuc0T2"
      },
      "source": [
        "## Part 3. Model 구조 만들기\n",
        "\n",
        "* 본 태스크를 위한 모델을 작성해주세요.\n",
        "* 예시로 작성된 class 외 새로운 class 를 정의해도 됩니다.\n",
        "* 하이퍼파라미터도 수정하거나 새로 추가하여 사용하셔도 됩니다.\n",
        "* **작성 모델 코드에 대한 간단한 설명을 보고서에 작성해주세요.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJRJL7vkc0T2"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    #################################################\n",
        "    ### 본 태스크를 위한 모델을 만들어주세요.              ###\n",
        "    ### Arguments 는 본인 모델에 맞게 추가/수정해주세요.   ###\n",
        "    #################################################\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n",
        "\n",
        "    def forward(self, text):\n",
        "        return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fObWJhcHa6t"
      },
      "source": [
        "#################################################\n",
        "### 아래 파라미터를 수정하거나, 새로 추가해서 사용하세요.  ###\n",
        "#################################################\n",
        "\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "OUTPUT_DIM = 4\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 128\n",
        "N_HEADS = 4\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qbyqHrbc0T3"
      },
      "source": [
        "###################################################\n",
        "### 예시로 적힌 Arguments 를 앞에 정의한 Model 에 맞게  ###\n",
        "###    추가/수정하여 model 을 선언하세요.              ###\n",
        "###################################################\n",
        "\n",
        "model = Model(INPUT_DIM,\n",
        "            EMBEDDING_DIM,\n",
        "            HIDDEN_DIM,\n",
        "            OUTPUT_DIM,\n",
        "            N_LAYERS,\n",
        "            BIDIRECTIONAL,\n",
        "            DROPOUT,\n",
        "            PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbgVPTqTc0T4"
      },
      "source": [
        "# GloVe embedding 을 가져오는 부분입니다. 해당 부분은 수정하지 마세요.\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7c6g8l5c0T4"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ID0sZn0Osbk"
      },
      "source": [
        "## Part 4. Train, Eval, and Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5ntUeQvEC7w"
      },
      "source": [
        "* 실습 시간에 했던 Sentiment Analysis 와 달리 본 태스크는 label 이 4가지인 Multiclass classification 입니다. 이에 따라 loss 를 Cross Entropy 로 계산합니다.\n",
        "* cross entropy: https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
        "* accuracy 계산시 각 인스턴스에 대한 label 은 model 로 부터 나온 output 중 가장 큰 값을 가진 label 을 할당합니다. 이때 torch.argmax 사용합니다.\n",
        "* torch.argmax: https://pytorch.org/docs/stable/generated/torch.argmax.html 중 아래 예시를 참고하세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uNRFBKic0T4"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model= model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woxFrZckak3L"
      },
      "source": [
        "### 4-1. 학습에 필요한 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBrNoQzuc0T4"
      },
      "source": [
        "def calculate_accuracy(preds, y):\n",
        "    ##################################################\n",
        "    ## Accuracy 를 측정하는 함수를 작성해주세요             ##\n",
        "    ## torch.argmax 를 사용하여 모델에서 출력한 output 중  ##\n",
        "    ##    가장 큰 값의 인덱스를 label 로 할당합니다.        ##\n",
        "    #################################################\n",
        "\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcrvOOd6c0T5"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        predictions = model(batch.text[0]).squeeze(1)\n",
        "\n",
        "        loss = criterion(predictions, batch.label)\n",
        "\n",
        "        acc = calculate_accuracy(predictions, batch.label)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLYBl8S8c0T5"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text[0]).squeeze(1)\n",
        "\n",
        "            loss = criterion(predictions, batch.label)\n",
        "\n",
        "            acc = calculate_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKdDAriwafLD"
      },
      "source": [
        "### 4-2. Start training!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1HOESu8c0T6",
        "collapsed": true
      },
      "source": [
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, val_iterator, criterion)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'trans-model.pt')\n",
        "\n",
        "    print('Epoch: {:02}'.format(epoch+1))\n",
        "    print('\\tTrain Loss: {:.3f} | Train Acc: {:.2f}%'.format(train_loss, train_acc*100))\n",
        "    print('\\t Val. Loss: {:.3f} |  Val. Acc: {:.2f}%'.format(valid_loss, valid_acc*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ayz2JoaNTaOG"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFFMYBxTTsHd"
      },
      "source": [
        "### 4-3. Predict\n",
        "* y_train, y_val 전처리 단계에서 string 형태의 카테고리를 1-4 로 label 을 변환했는데, 결과를 출력하기 위해서는 label 을 다시 string 형태의 카테고리로 변환해야합니다.\n",
        "* 이를 위해 앞서 정의한 LABEL_MAPPING 의 reverse dictionary, LABEL_REV_MAPPING 을 정의합니다.\n",
        "* 테스트 데이터인 X_test 는 리스트 형태로 데이터가 존재하는데, 리스트 내 각 원소를 순차적으로 1) 토큰화, 2) 모델 입력, 3) 가장 높은 확률을 가진 label 출력, 4) label 을 카테고리로 변환하여 리스트로 리턴하는 함수를 정의합니다.\n",
        "* 리스트 형태의 결과물을 csv 로 저장한 후, output.csv 를 kaggle inclass 에 제출합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr-1uF5V9go6"
      },
      "source": [
        "LABEL_INV_MAPPING = {v:k for k, v in LABEL_MAPPING.items()}\n",
        "LABEL_INV_MAPPING"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NqD0tFsc0T6"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def predict(model, X_test):\n",
        "    all_preds = []\n",
        "    model.eval()\n",
        "    for seq in X_test:\n",
        "        #######################################################################\n",
        "        ## X_test 의 원소인 seq 를 1) 토큰화, 2) 모델 입력, 3) 가장 높은 확률을 가진    ##\n",
        "        ##  label 출력, 4) label 을 카테고리로 변환하여, 5) label 리스트에 추가합니다.  ##\n",
        "        ##  1-3 에 해당하는 작업을 코드로 작성해주세요.                               ##\n",
        "        ##  3 의 결과물을 max_prob_label 에 저장해주세요.                          ##\n",
        "        #######################################################################\n",
        "\n",
        "        # 4, 5번에 대한 코드\n",
        "        pred = max_prob_label.item()\n",
        "        all_preds.append(LABEL_INV_MAPPING[int(pred)])\n",
        "    pd.DataFrame(all_preds, columns=['Category'],\n",
        "                 index=[i for i in range(len(all_preds))]).to_csv('./iab_challenge_23/output.csv', index_label=\"Index\")\n",
        "    print(\"Submit your output.csv into kaggle in-class\")\n",
        "    return all_preds[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCIlOxEQ4Qew"
      },
      "source": [
        "# 이 셀을 실행하면 iab_challenge_20 폴더 안에 output.csv 가 생성됩니다.\n",
        "# 해당 파일을 다운로드하여 kaggle inclass 에 제출하세요.\n",
        "\n",
        "predict(model, X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcEzr_gYaXze"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yQ4yUmoYFaT"
      },
      "source": [
        "## 주의사항\n",
        "* 노트북 상단에 kaggle 제출시 사용한 ID 를 기입해주셔야합니다.\n",
        "* 제출 목록과 기한을 다시 한번 확인해주세요.\n",
        "  * output.csv: 오늘 17:30 까지 kaggle inclass 에 제출\n",
        "  * 본 노트북: 오늘 17:30 까지 ETL 에 제출\n",
        "  * 코드에 대한 보고서: 내일 정오(6/17 11:59 AM)까지 ETL 에 제출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJnbC_VUYjyv"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}