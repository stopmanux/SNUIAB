{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgcsFwD3vDxe"
      },
      "source": [
        "# IoT·인공지능·빅데이터 개론 및 실습 <br> 3/8 Logistic Regerssion & Neural Network with Scikit-Learn\n",
        "\n",
        "Adapted by Seonwoo Min from the \"An Introduction to Machine Learning with Scikit-learn\" tutorial (http://scikit-learn.org/stable/tutorial/basic/tutorial.html).\n",
        "\n",
        "In this excercise, we will cover:\n",
        "\n",
        "* Loading an example dataset & preprocessing\n",
        "* Logistic regression & neural network models in scikit-learn\n",
        "* Model training & prediction & evaluation\n",
        "* Model save & load\n",
        "* Homework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ0nj5O9vDxh"
      },
      "source": [
        "## 1. Loading an example dataset & preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOluQdMFvDxh",
        "outputId": "c3b3c937-21eb-4583-a472-0f2740e7e34f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "data = load_digits()\n",
        "print(data.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faY5Va7ZvDxi",
        "outputId": "7fa903d4-eccf-4b43-fada-9132622a47b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data:  (1797, 64)\n",
            "Label: (1797,)\n",
            "[0 1 2 3 4 5 6 7 8 9]\n",
            "178\n",
            "In class 0, 178\n",
            "In class 1, 182\n",
            "In class 2, 177\n",
            "In class 3, 183\n",
            "In class 4, 181\n",
            "In class 5, 182\n",
            "In class 6, 181\n",
            "In class 7, 179\n",
            "In class 8, 174\n",
            "In class 9, 180\n"
          ]
        }
      ],
      "source": [
        "# Data shape & statistics\n",
        "print(\"Data: \", data['data'].shape) #data 차원이 64차원(8*8의 이미지), 1797개\n",
        "print(\"Label:\", data['target'].shape) #numpy에서 형태를 알려줌\n",
        "\n",
        "# Print the number of samples for each class\n",
        "import numpy as np\n",
        "#################### To Do #################################\n",
        "\n",
        "print(np.unique(data['target'])) #1797개. unique : data target array 내에 어떤 unique한 값이 존재하는가?\n",
        "\n",
        "print(np.sum(data['target'] == 0))\n",
        "\n",
        "for i in range(10):\n",
        "  wh = data['target'] == i #booloin 값이 일단 wh에 반환되는데\n",
        "  count = np.sum(wh) #sum을 통해서 wh의 true 갯수를 count에 넣어 준다.\n",
        "  print('In class %d, %d' % (i, count))\n",
        "  \n",
        "############################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "-u6AbU4tvDxj",
        "outputId": "6aae2d60-903f-4517-f59e-536ef0de23c3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAK0klEQVR4nO3dX4hc5RnH8d+vq6G1Wl2aUCQJ3QgSCIUaHQKSIjSuJVbRXhRJQKFSSC6qKC1I7F3vzI3YiyKRqBVMlTQqiFhtJEortNbdmLYm0ZKuKW4wTUIi/rloiD692AlEu3bPzJ7znrMP3w8Ed3eWeZ8hfnNmzs6e1xEhAHl8qe0BANSLqIFkiBpIhqiBZIgaSOa8Ju508eLFMTY21sRdt+ro0aNF1zty5EixtRYtWlRsrVWrVhVba2RkpNhaJR0+fFgnTpzwbLc1EvXY2JgmJiaauOtWbd26teh6W7ZsKbbW0qVLi621Z8+eYmuNjo4WW6ukXq/3hbfx9BtIhqiBZIgaSIaogWSIGkiGqIFkiBpIhqiBZIgaSKZS1LbX237b9iHb5d7mBGBgc0Zte0TSryRdL2mVpI22y715F8BAqhyp10g6FBFTEXFa0pOSbm52LADDqhL1UknvnvP5dP9rn2F7k+0J2xPHjx+vaz4AA6rtRFlEPBQRvYjoLVmypK67BTCgKlEfkbT8nM+X9b8GoIOqRP26pMttr7C9SNIGSc82OxaAYc15kYSIOGP7DkkvShqR9EhE7G98MgBDqXTlk4h4XtLzDc8CoAa8owxIhqiBZIgaSIaogWSIGkiGqIFkiBpIppEdOkoquYvFzp07i60lSdu2bSu21ubNm4utNTk5WWyt8fHxYmt1BUdqIBmiBpIhaiAZogaSIWogGaIGkiFqIBmiBpIhaiAZogaSqbJDxyO2j9l+s8RAAOanypH615LWNzwHgJrMGXVE/EHSyQKzAKhBba+p2XYH6Aa23QGS4ew3kAxRA8lU+ZHWE5L+JGml7WnbP25+LADDqrKX1sYSgwCoB0+/gWSIGkiGqIFkiBpIhqiBZIgaSIaogWQcEbXfaa/Xi4mJidrvdzZTU1NF1pGk0dHRYmtJ0lVXXVV0vVJK/p1l1ev1NDEx4dlu40gNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyVa5Rttz2y7YP2N5v+64SgwEYzpzXKJN0RtLPImKv7YskTdreHREHGp4NwBCqbLvzXkTs7X/8oaSDkpY2PRiA4Qz0mtr2mKTVkl6b5Ta23QE6oHLUti+U9JSkuyPig8/fzrY7QDdUitr2+ZoJekdEPN3sSADmo8rZb0t6WNLBiLi/+ZEAzEeVI/VaSbdJWmd7X//P9xueC8CQqmy786qkWS+bAqB7eEcZkAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8lU+X3qTrvsssuKrVV6D6h33nmn2Frj4+PF1jp16lSxtUrvf9YFHKmBZIgaSIaogWSIGkiGqIFkiBpIhqiBZIgaSIaogWSqXHjwy7b/Yvuv/W13flFiMADDqfI20f9IWhcRH/UvFfyq7d9FxJ8bng3AEKpceDAkfdT/9Pz+n2hyKADDq3ox/xHb+yQdk7Q7Ith2B+ioSlFHxCcRcYWkZZLW2P7WLN/DtjtABwx09jsi3pf0sqT1jUwDYN6qnP1eYvuS/sdfkXSdpLcangvAkKqc/b5U0mO2RzTzj8DOiHiu2bEADKvK2e+/aWZPagALAO8oA5IhaiAZogaSIWogGaIGkiFqIBmiBpIhaiCZBb/tTkklt/iRpJMnTxZbq+S2OyXXeumll4qtJXVjmx+O1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJFM56v4F/d+wzUUHgQ4b5Eh9l6SDTQ0CoB5Vt91ZJukGSdubHQfAfFU9Uj8g6R5Jn37RN7CXFtANVXbouFHSsYiY/H/fx15aQDdUOVKvlXST7cOSnpS0zvbjjU4FYGhzRh0R90bEsogYk7RB0p6IuLXxyQAMhZ9TA8kMdDmjiHhF0iuNTAKgFhypgWSIGkiGqIFkiBpIhqiBZIgaSIaogWTYdqfDSm7hUnJ7ms2bNxdba+vWrcXWkqT77ruv6Hqz4UgNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyld4m2r+S6IeSPpF0JiJ6TQ4FYHiDvPf7uxFxorFJANSCp99AMlWjDkm/tz1pe9Ns38C2O0A3VI36OxFxpaTrJf3E9jWf/wa23QG6oVLUEXGk/99jkp6RtKbJoQAMr8oGeV+1fdHZjyV9T9KbTQ8GYDhVzn5/Q9Izts9+/28i4oVGpwIwtDmjjogpSd8uMAuAGvAjLSAZogaSIWogGaIGkiFqIBmiBpIhaiAZtt0ZwJYtW4quNz4+XmytU6dOFVtr9+7dxda65ZZbiq3VFRypgWSIGkiGqIFkiBpIhqiBZIgaSIaogWSIGkiGqIFkiBpIplLUti+xvcv2W7YP2r666cEADKfqe79/KemFiPih7UWSLmhwJgDzMGfUti+WdI2kH0lSRJyWdLrZsQAMq8rT7xWSjkt61PYbtrf3r//9GWy7A3RDlajPk3SlpAcjYrWkjyX9z+8gsu0O0A1Vop6WNB0Rr/U/36WZyAF00JxRR8RRSe/aXtn/0rWSDjQ6FYChVT37faekHf0z31OSbm9uJADzUSnqiNgnqdfsKADqwDvKgGSIGkiGqIFkiBpIhqiBZIgaSIaogWSIGkiGvbQGMDo6WnS9TZs2FV2vlJL7W23btq3YWl3BkRpIhqiBZIgaSIaogWSIGkiGqIFkiBpIhqiBZIgaSGbOqG2vtL3vnD8f2L67wGwAhjDn20Qj4m1JV0iS7RFJRyQ90+xYAIY16NPvayX9MyL+1cQwAOZv0Kg3SHpithvYdgfohspR96/5fZOk3852O9vuAN0wyJH6ekl7I+LfTQ0DYP4GiXqjvuCpN4DuqBR1f+va6yQ93ew4AOar6rY7H0v6esOzAKgB7ygDkiFqIBmiBpIhaiAZogaSIWogGaIGkiFqIBlHRP13ah+XNOivZy6WdKL2Yboh62PjcbXnmxEx629ONRL1MGxPRESv7TmakPWx8bi6iaffQDJEDSTTpagfanuABmV9bDyuDurMa2oA9ejSkRpADYgaSKYTUdteb/tt24dsb2l7njrYXm77ZdsHbO+3fVfbM9XJ9ojtN2w/1/YsdbJ9ie1dtt+yfdD21W3PNKjWX1P3Nwj4h2YulzQt6XVJGyPiQKuDzZPtSyVdGhF7bV8kaVLSDxb64zrL9k8l9SR9LSJubHueuth+TNIfI2J7/wq6F0TE+y2PNZAuHKnXSDoUEVMRcVrSk5JubnmmeYuI9yJib//jDyUdlLS03anqYXuZpBskbW97ljrZvljSNZIelqSIOL3Qgpa6EfVSSe+e8/m0kvzPf5btMUmrJb3W8ih1eUDSPZI+bXmOuq2QdFzSo/2XFtv7F91cULoQdWq2L5T0lKS7I+KDtueZL9s3SjoWEZNtz9KA8yRdKenBiFgt6WNJC+4cTxeiPiJp+TmfL+t/bcGzfb5mgt4REVkur7xW0k22D2vmpdI624+3O1JtpiVNR8TZZ1S7NBP5gtKFqF+XdLntFf0TExskPdvyTPNm25p5bXYwIu5ve566RMS9EbEsIsY083e1JyJubXmsWkTEUUnv2l7Z/9K1khbcic1K1/1uUkScsX2HpBcljUh6JCL2tzxWHdZKuk3S323v63/t5xHxfHsjoYI7Je3oH2CmJN3e8jwDa/1HWgDq1YWn3wBqRNRAMkQNJEPUQDJEDSRD1EAyRA0k818YrbRZi+CshQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#############################################################\n",
        "# Data Visaulization\n",
        "#############################################################\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#################### To Do ################################# \n",
        "# Hint: plt.imshow(data['data'][i].reshape(8,8), cmap=plt.cm.gray_r)\n",
        "plt.imshow(data['data'][3].reshape(8,8), cmap=plt.cm.gray_r) #i를 넣을 때마다 plot의 형태가 바뀜\n",
        "plt.show() #분리해야 되는 데이터는 숫자 데이터(8*8 이미지를 한 줄로 나열한 것을 data로 갖고있음.)\n",
        "############################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EROtR0gvDxj",
        "outputId": "da5c0313-cb3e-4f7d-a3e6-41145e1d0db5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(200, 64)\n",
            "(1597, 64)\n"
          ]
        }
      ],
      "source": [
        "#############################################################\n",
        "# 1st Preprocessing\n",
        "# Use the first 20 samples in each clss as test data\n",
        "# Use the others as training data\n",
        "#############################################################\n",
        "train_data = []\n",
        "test_data = []\n",
        "\n",
        "train_target = []\n",
        "test_target = []\n",
        "#################### To Do #################################\n",
        "\n",
        "N = len(data['data'])\n",
        "for c in range(10):\n",
        "  is_in_this_class = data['target'] == c  # boolean (1797,)\n",
        "  \n",
        "  data_in_this_class = data['data'][is_in_this_class]  # (178, 64)\n",
        "  target_in_this_class = data['target'][is_in_this_class]\n",
        "  \n",
        "  test_data.append(data_in_this_class[:20])\n",
        "  train_data.append(data_in_this_class[20:])\n",
        "  test_target.append(target_in_this_class[:20])\n",
        "  train_target.append(target_in_this_class[20:])\n",
        "\n",
        "# concatenate 전에는 (10, 20, 64)\n",
        "\n",
        "test_data = np.concatenate(test_data)\n",
        "train_data = np.concatenate(train_data)\n",
        "test_target = np.concatenate(test_target)\n",
        "train_target = np.concatenate(train_target)\n",
        "\n",
        "############################################################\n",
        "\n",
        "print(test_data.shape)\n",
        "print(train_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHcWORlpvDxk",
        "outputId": "415ffe20-14bc-4f14-f685-23b918578e62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(40, 64)\n",
            "(320, 64)\n"
          ]
        }
      ],
      "source": [
        "#############################################################\n",
        "# 2nd Preprocessing\n",
        "# Let's use only 2 and 3 for binary classification\n",
        "#############################################################\n",
        "\n",
        "#################### To Do #################################\n",
        "train_data23 = []\n",
        "test_data23 = []\n",
        "\n",
        "train_target23 = []\n",
        "test_target23 = []\n",
        "#################### To Do #################################\n",
        "\n",
        "N = len(data['data'])\n",
        "for c in [2, 3]: #여기만 차이 있음....\n",
        "  is_in_this_class = data['target'] == c  # boolean (1797,)\n",
        "  \n",
        "  data_in_this_class = data['data'][is_in_this_class]  # (178, 64)\n",
        "  target_in_this_class = data['target'][is_in_this_class]\n",
        "  \n",
        "  test_data23.append(data_in_this_class[:20])\n",
        "  train_data23.append(data_in_this_class[20:])\n",
        "  test_target23.append(target_in_this_class[:20])\n",
        "  train_target23.append(target_in_this_class[20:])\n",
        "\n",
        "test_data23 = np.concatenate(test_data23)\n",
        "train_data23 = np.concatenate(train_data23)\n",
        "test_target23 = np.concatenate(test_target23)\n",
        "train_target23 = np.concatenate(train_target23)\n",
        "\n",
        "############################################################\n",
        "\n",
        "print(test_data23.shape)\n",
        "print(train_data23.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Wxg-r5avDxk"
      },
      "source": [
        "## 2. Logistic regression & neural network models in scikit-learn\n",
        "\n",
        "For full documentations refer to the following links: <br>\n",
        "Logistic Regression: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html <br>\n",
        "Neural network: http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSOPeiyZvDxl"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "LR = LogisticRegression(max_iter=1000, solver='sag')\n",
        "NN = MLPClassifier(hidden_layer_sizes=(10), activation='relu', learning_rate_init=0.01, max_iter=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGAEwJ_4vDxl"
      },
      "source": [
        "## 3. Model training & prediction & evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UW25GJARvDxm",
        "outputId": "fc2b1370-5c96-40fb-e886-995cbe70610a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc : 1.0\n",
            "test_acc  : 0.975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#############################################################\n",
        "# Logistic regression model\n",
        "#############################################################\n",
        "# Training\n",
        "LR = LogisticRegression(max_iter=1000, solver='sag') #logisticregression 저기 max iter 을 충분히 늘려서 뭔가를 실행해줌.\n",
        "#solver는 optimizer의 종류임\n",
        "LR.fit(train_data23, train_target23) \n",
        "\n",
        "# Prediction\n",
        "train_predict23 = LR.predict(train_data23)\n",
        "train_prob23 = LR.predict_proba(train_data23)\n",
        "\n",
        "test_predict23 = LR.predict(test_data23)\n",
        "test_prob23 = LR.predict_proba(test_data23)\n",
        "\n",
        "#print(\"test_target     :\", test_target23)\n",
        "#print(\"test_prediction :\", test_predict23)\n",
        "#print(\"train_prob :\", train_prob23[:10])\n",
        "#print(\"test_prob :\", test_prob23[:10])\n",
        "\n",
        "#################### To Do #################################\n",
        "\n",
        "is_correct = train_predict23 == train_target23\n",
        "train_acc23 = np.mean(is_correct)\n",
        "is_correct = test_predict23 == test_target23\n",
        "test_acc23 = np.mean(is_correct)\n",
        "\n",
        "\n",
        "############################################################\n",
        "\n",
        "print(\"train_acc :\", train_acc23) #이걸 하는게 underfitting에 대한 여부를 파악하려고 함.\n",
        "print(\"test_acc  :\", test_acc23)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4_maCTTvDxm",
        "outputId": "0dee2cee-fc0d-4566-ba52-69d7b2458b97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc : 1.0\n",
            "test_acc  : 0.975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#############################################################\n",
        "# Neural network model\n",
        "############################################################# \n",
        "\n",
        "#################### To Do #################################\n",
        "NN = MLPClassifier(hidden_layer_sizes=(10,), activation='tanh', learning_rate_init=1e-2, max_iter=100) \n",
        "#다양한 parameter을 바꾸면서 추후 homework를 풀 때 key가 될 듯 함. layer sizes는 일정량 이상으로, \n",
        "NN.fit(train_data23, train_target23)\n",
        "\n",
        "# Prediction\n",
        "train_predict23 = NN.predict(train_data23)\n",
        "train_prob23 = NN.predict_proba(train_data23)\n",
        "test_predict23 = NN.predict(test_data23)\n",
        "test_prob23 = NN.predict_proba(test_data23)\n",
        "#print(\"test_target     :\", test_target23)\n",
        "#print(\"test_prediction :\", test_predict23)\n",
        "#print(\"train_prob :\", train_prob23[:10])\n",
        "#print(\"test_prob :\", test_prob23[:10])\n",
        "\n",
        "is_correct = train_predict23 == train_target23\n",
        "train_acc23 = np.mean(is_correct)\n",
        "is_correct = test_predict23 == test_target23\n",
        "test_acc23 = np.mean(is_correct)\n",
        "\n",
        "\n",
        "############################################################ Neural netowork model이 더 맞는 것 같음.\n",
        "\n",
        "print(\"train_acc :\", train_acc23)\n",
        "print(\"test_acc  :\", test_acc23)\n",
        "############################################################ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRrl3d76vDxm"
      },
      "source": [
        "## 4. Model save & load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPljItYQvDxm"
      },
      "outputs": [],
      "source": [
        "# from sklearn.externals import joblib\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "if not os.path.exists('models'):\n",
        "    os.makedirs('models')\n",
        "    \n",
        "# save\n",
        "joblib.dump(NN, 'models/NN23.joblib') \n",
        "\n",
        "# load\n",
        "NN_load = joblib.load('models/NN23.joblib') \n",
        "\n",
        "#################### To Do #################################\n",
        "train_predict23 = NN_load.predict(train_data23)\n",
        "train_prob23 = NN_load.predict_proba(train_data23)\n",
        "\n",
        "############################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNoBFCEvvDxn"
      },
      "source": [
        "## 5. Homework\n",
        "Now it's your job to experiment with models and achieve higher accuracy on the  **<font color=red>on the entire dataset</font>**. <br>\n",
        "Try different hyperparameter configurations and save the final model as \"final_model.joblib\" <br>\n",
        "Submit the current **notebook file and the saved final model** on ETL.\n",
        "* Maximum 10 points for >= 97% accuracy on the test set\n",
        "* Maximum 8 points for >= 96% accuracy on the test set\n",
        "* Maximum 6 points for >= 95% accuracy on the test set\n",
        "* Maximum 4 points for >= 94% accuracy on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72NYJ0OkvDxn",
        "outputId": "6d23658f-511e-400e-fc4e-00b835b8e00e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_acc : 1.0\n",
            "test_acc  : 0.97\n"
          ]
        }
      ],
      "source": [
        "#############################################################\n",
        "# Try different hyperparameters\n",
        "# Final model training\n",
        "############################################################# 전체 숫자에 대한 classfier test 종류는 아무거나상관없음,\n",
        "#class별로 20개만 test data로 들어감.\n",
        "\n",
        "\n",
        "#################### To Do #################################\n",
        "train_data = []\n",
        "test_data = []\n",
        "\n",
        "train_target = []\n",
        "test_target = []\n",
        "\n",
        "N = len(data['data'])\n",
        "for c in range(10):\n",
        "  is_in_this_class = data['target'] == c  # boolean (1797,)\n",
        "  \n",
        "  data_in_this_class = data['data'][is_in_this_class]  # (178, 64)\n",
        "  target_in_this_class = data['target'][is_in_this_class]\n",
        "  \n",
        "  test_data.append(data_in_this_class[:20])\n",
        "  train_data.append(data_in_this_class[20:])\n",
        "  test_target.append(target_in_this_class[:20])\n",
        "  train_target.append(target_in_this_class[20:])\n",
        "\n",
        "\n",
        "test_data = np.concatenate(test_data)\n",
        "train_data = np.concatenate(train_data)\n",
        "test_target = np.concatenate(test_target)\n",
        "train_target = np.concatenate(train_target)\n",
        "\n",
        "NN = MLPClassifier(hidden_layer_sizes=(50), activation='tanh', learning_rate_init=1e-3, max_iter=1200) \n",
        "NN.fit(train_data, train_target)\n",
        "\n",
        "# NN = MLPClassifier(hidden_layer_sizes=(33), activation='tanh', learning_rate_init=1e-3, max_iter=1200) 0.965 최고기록\n",
        "\n",
        "train_predict = NN.predict(train_data)\n",
        "train_prob = NN.predict_proba(train_data)\n",
        "test_predict = NN.predict(test_data)\n",
        "test_prob = NN.predict_proba(test_data)\n",
        "\n",
        "is_correct = train_predict == train_target\n",
        "train_acc = np.mean(is_correct)\n",
        "is_correct = test_predict == test_target\n",
        "test_acc = np.mean(is_correct)\n",
        "\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "if not os.path.exists('models'):\n",
        "    os.makedirs('models')\n",
        "    \n",
        "# save\n",
        "joblib.dump(NN, 'models/NN23.joblib') \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"train_acc :\", train_acc)\n",
        "print(\"test_acc  :\", test_acc)\n",
        "############################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AnhHODrvDxn",
        "outputId": "ba51c649-f2e3-4b76-b3ed-d978d82f85cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc : 1.0\n",
            "test_acc  : 0.97\n"
          ]
        }
      ],
      "source": [
        "#############################################################\n",
        "# Final model test\n",
        "# Load the final model and obatin the test accuracy\n",
        "############################################################# joblib는 굳이 안해도되지만 일단 해보기.\n",
        "\n",
        "\n",
        "# load\n",
        "NN_load = joblib.load('models/NN23.joblib') \n",
        "\n",
        "#################### To Do #################################\n",
        "train_predict = NN_load.predict(train_data)\n",
        "train_prob = NN_load.predict_proba(train_data)\n",
        "test_predict = NN_load.predict(test_data)\n",
        "test_prob = NN_load.predict_proba(test_data)\n",
        "\n",
        "is_correct = train_predict == train_target\n",
        "train_acc = np.mean(is_correct)\n",
        "is_correct = test_predict == test_target\n",
        "test_acc = np.mean(is_correct)\n",
        "\n",
        "print(\"train_acc :\", train_acc)\n",
        "print(\"test_acc  :\", test_acc)\n",
        "\n",
        "############################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aYuxARvvDxo"
      },
      "source": [
        "### Describe what you did here\n",
        "In this cell you should also write an explanation of what you did, any additional features that you implemented, and any visualizations or graphs that you make in the process of training and evaluating your model.\n",
        "* Maximum 10 points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkZtLjxivDxo"
      },
      "source": [
        "앞서 neural networking이 logistic regression model보다 성능이 더 뛰어남을 고려하여, neural networking을 통해서 model을 만들어보기로 했다.그리하여 activation='tanh' 함수 형태는 그대로 두고, hidden layer 개수를 1개씩 늘려 33개로 두었다. max_iter은 100 단위씩 높여보면서 가장 높은 결과가 나오는 1200으로 나오도록 찾았고, learing rate init도 조절하여 1e-3이 나오도록 했다.\n",
        "그 중에서 가장 좋은 결과가 나오도록 반복 했다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}