SQL을 다뤄야 하는데, 파이썬만 하다가 SQL을 처음 하다보니 매우 어려울 것인데,
아래 채점 기준표를 잘 살펴보고 homework solution을 보시길 바란다.




[숙제 환경 셋팅]
제공된 ipynb notebook 을 colab으로 실행

 

Problem 1. SparkSQL 

WikipediaTable에서 project='en' 에 해당하는 row들 중 size 항목이 1000 이상 10000 미만인 값들을 title 기준으로 내림차순 정렬한 표

⇒ 결과: project, title, size column을 갖는 table 

 

Problem 2. SparkSQL 

WikipediaTable과 다음의 OwnerTable을 JOIN한 후 각 owner 당 count의 평균값을 구한 표

⇒ 결과: owner, avg_count column을 갖는 table

 

OwnerTable

title

owner

Honne

Lila

Sia

Jane

Ryuichi_Sakamoto

Sam

 

Problem 3. SparkRDD 

wikipedia_dataset_sample을 사용하여, project별로 count 필드의 median 값을 구하고, notebook상에 출력하는 RDD 프로그램을 작성하여라.

 

주의: 

count값들 중 중복된 값이 있는 경우, 단일한 값인 것으로 가정
ex) project=en인 데이터가 모두 (‘en’, 1L), (‘en’, 1L), (‘en’, 2L), (‘en’, 3L) 라고 할 때, (‘en’, 1L), (‘en’, 2L), (‘en’, 3L)로 가정하고 계산할 것
median을 구해주는 Spark 내장 함수 또는 기타 라이브러리 함수를 사용하면 0점
ex) approxQuantile, NumPy.median, …
collect()해서 가져온 값에서 median을 구하면 0점 
 

Hint:
스파크의 groupByKey(), mapValues(..), distinct() 를 사용하셔서 median을 구하시면 됩니다.
python의 sort()함수를 사용하시는 것은 가능합니다.
짝수 개의 element인 경우에는, median 두 개의 값의 평균을 구해주세요.
ex) [1,2,3,4] => (2+3)/2
