{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ec1NCtLafD2"
      },
      "source": [
        "# 1. Preparations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFpwJWt6H8i-"
      },
      "source": [
        "### 1-1. Import Libraries\n",
        "- 데이터셋 다운로드와 전처리를 쉽게 하는 torchtext 라이브러리를 import 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izLU93pPYJEx",
        "outputId": "e15a7253-8b3c-4faa-9478-504ad96bf1df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.11.0\n",
            "  Downloading torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0) (4.5.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.11.0 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.11.0 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.11.0 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.11.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.27.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Collecting sentencepiece (from torchtext==0.6.0)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.5.0)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.15.2\n",
            "    Uninstalling torchtext-0.15.2:\n",
            "      Successfully uninstalled torchtext-0.15.2\n",
            "Successfully installed sentencepiece-0.1.99 torchtext-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.11.0\n",
        "!pip install torchtext==0.6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fuWiZzTJIHlX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchtext import data, datasets\n",
        "import random\n",
        "import time\n",
        "import spacy\n",
        "import numpy as np\n",
        "from torch import Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlBRh_erIV5Y"
      },
      "source": [
        "### 1-2. Load data\n",
        "- Field 를 정의합니다.\n",
        "- IMDB 데이터를 다운받습니다.\n",
        "- Train,valid,test 데이터셋으로 split 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1qAjGhs_momr"
      },
      "outputs": [],
      "source": [
        "TEXT = data.Field(include_lengths=True)\n",
        "LABEL = data.LabelField(dtype = torch.float) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lAyLqGf_sOgf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be84f511-eaf3-433e-f84b-c4103619ff8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:08<00:00, 9.37MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download IMDB data (about 14mins)\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CvW4_Eard8lj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "5bbd127b-a380-4340-eb0d-98eae6f4d86d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f7b00994b29e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Idle Function for maintaining Runtime Session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Idle Function for maintaining Runtime Session\n",
        "while True:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xhhfnEZYsld1"
      },
      "outputs": [],
      "source": [
        "# Set the random seed\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9dDuDBdvsOmk"
      },
      "outputs": [],
      "source": [
        "# Split train and valid data\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NdLyvaV6o-TY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb974828-9e31-4665-b3f2-03bdb070e032"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ]
        }
      ],
      "source": [
        "print('Number of training examples: {}'.format(len(train_data)))\n",
        "print('Number of validation examples: {}'.format(len(valid_data)))\n",
        "print('Number of testing examples: {}'.format(len(test_data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-IEhTw1Z5k3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa6ecd0f-3471-4007-fb8d-7753ea3083f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['Seriously,', 'I', 'can', 'easily', 'stomach', 'a', 'lot', 'of', 'on', 'screen', 'blood,', 'gore', 'and', 'repulsiveness,', 'but', 'what', 'really', 'makes', 'this', 'film', 'disturbing', '&', 'uncomfortable', 'to', 'watch', 'is', 'how', 'the', 'doctor', 'character', 'keeps', 'on', 'rambling', 'about', 'the', 'physical', 'damage', 'done', 'to', 'raped', 'women.', 'He,', 'John', 'Cassavetes', 'of', '\"Rosemary\\'s', 'Baby\",', 'talks', 'about', 'ruptured', 'uterus,', 'dry', 'intercourse', 'and', 'massive', 'loads', 'of', 'reddish', '(?)', 'sperm', 'like', 'they', 'are', 'the', 'most', 'common', 'little', 'ailments', 'in', 'the', 'world', 'of', 'medicine.', 'That', 'being', 'said,', '\"Incubus\"', 'is', 'an', 'ultimately', 'STRANGE', 'horror', 'effort.', 'It', \"isn't\", 'necessarily', 'awful', '\\x96', 'although', 'it', \"isn't\", 'very', 'good,', 'neither', '\\x96', 'but', 'just', 'plain', 'weird.', 'The', 'muddled', '&', 'incoherent', 'script', 'initially', 'revolves', 'on', 'the', 'hunt', 'for', 'a', 'rapist-killer', 'of', 'flesh', 'and', 'blood', '(even', 'though', 'the', 'title', 'clearly', 'suggests', 'the', 'involvement', 'of', 'a', 'supernatural', 'creature)', 'and', 'it', 'never', 'seems', 'to', 'stop', 'introducing', 'new', 'characters.', 'None', 'of', 'these', 'characters,', 'especially', 'not', 'the', 'main', 'ones,', 'come', 'across', 'as', 'sympathetic', 'and', 'for', 'some', 'never-explained', 'reason', 'they', 'all', 'seem', 'to', 'keep', 'dark', 'secrets.', 'The', 'aforementioned', 'doctor', 'has', 'an', 'odd', 'interpretation', 'of', 'daughter-love', 'and', 'continuously', 'behaves', 'like', \"he's\", 'a', 'suspect', 'himself,', 'the', \"town's\", 'sheriff', '(John', 'Ireland)', 'appears', 'to', 'be', 'in', 'a', 'constant', 'state', 'of', 'drunkenness', 'and', \"doesn't\", 'even', 'seem', 'to', 'care', 'about', 'who', 'keeps', 'raping', '&', 'killing', 'the', 'women', 'in', 'his', 'district,', 'the', 'female', 'reporter', 'is', 'even', 'too', 'weird', 'for', 'words', 'and', 'the', 'Galens', '(an', 'old', 'witch', 'and', 'her', 'grandson)', 'are', 'just', 'plain', 'spooky.', 'All', 'together', 'they', 'desperately', 'try', 'to', 'solve', 'the', 'mystery', 'of', 'whom', 'or', 'what', 'exactly', 'is', 'destroying', 'the', \"towns'\", 'women', 'reproducing', 'organs.', 'The', 'sequences', 'building', 'up', 'towards', 'the', 'rapes', '&', 'murders', 'are', 'admirably', 'atmospheric', 'and', 'the', 'vile', 'acts', 'themselves', 'are', 'bloody', 'and', 'unsettling.', 'Basically', 'these', 'are', 'very', 'positive', 'factors', 'in', 'a', 'horror', 'film,', 'but', 'the', 'narrative', 'structure', 'is', 'too', 'incoherent', 'and', 'the', 'characters', 'are', 'too', 'unsympathetic', 'for', '\"Incubus\"', 'to', 'be', 'a', 'really', 'good', 'film.', 'Also,', 'there', 'are', 'quite', 'a', 'few', 'tedious', 'parts', 'to', 'struggle', 'yourself', 'through', '(like', 'footage', 'of', 'a', 'Bruce', 'Dickinson', 'concert!)', 'and', 'the', 'usually', 'very', 'reliable', 'John', \"Hough's\", 'direction', 'is', 'nearly', 'unnoticeable.', 'The', 'final', 'shot', 'is', 'effectively', 'nightmarish,', 'though.', 'For', 'me', 'personally,', '\"Incubus\"', 'was', 'a', 'bit', 'of', 'a', 'disappointment,', 'but', 'there', 'are', 'still', 'several', 'enough', 'reasons', 'to', 'recommend', 'this', 'odd', 'piece', 'of', 'early', \"80's\", 'horror', 'to', 'open-minded', 'genre', 'fanatics.'], 'label': 'neg'}\n",
            "Seriously, I can easily stomach a lot of on screen blood, gore and repulsiveness, but what really makes this film disturbing & uncomfortable to watch is how the doctor character keeps on rambling about the physical damage done to raped women. He, John Cassavetes of \"Rosemary's Baby\", talks about ruptured uterus, dry intercourse and massive loads of reddish (?) sperm like they are the most common little ailments in the world of medicine. That being said, \"Incubus\" is an ultimately STRANGE horror effort. It isn't necessarily awful  although it isn't very good, neither  but just plain weird. The muddled & incoherent script initially revolves on the hunt for a rapist-killer of flesh and blood (even though the title clearly suggests the involvement of a supernatural creature) and it never seems to stop introducing new characters. None of these characters, especially not the main ones, come across as sympathetic and for some never-explained reason they all seem to keep dark secrets. The aforementioned doctor has an odd interpretation of daughter-love and continuously behaves like he's a suspect himself, the town's sheriff (John Ireland) appears to be in a constant state of drunkenness and doesn't even seem to care about who keeps raping & killing the women in his district, the female reporter is even too weird for words and the Galens (an old witch and her grandson) are just plain spooky. All together they desperately try to solve the mystery of whom or what exactly is destroying the towns' women reproducing organs. The sequences building up towards the rapes & murders are admirably atmospheric and the vile acts themselves are bloody and unsettling. Basically these are very positive factors in a horror film, but the narrative structure is too incoherent and the characters are too unsympathetic for \"Incubus\" to be a really good film. Also, there are quite a few tedious parts to struggle yourself through (like footage of a Bruce Dickinson concert!) and the usually very reliable John Hough's direction is nearly unnoticeable. The final shot is effectively nightmarish, though. For me personally, \"Incubus\" was a bit of a disappointment, but there are still several enough reasons to recommend this odd piece of early 80's horror to open-minded genre fanatics.\n"
          ]
        }
      ],
      "source": [
        "# print example\n",
        "print(vars(train_data.examples[0]))\n",
        "print(' '.join(vars(train_data.examples[0])['text']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEsf_UifafEH"
      },
      "source": [
        "### 1-3. Cuda Setup\n",
        "- GPU 사용을 위한 Cuda 설정\n",
        "- Colab 페이지 상단 메뉴>수정>노트설정에서 GPU 사용 설정이 선행되어야 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "W4BsnajZafEI"
      },
      "outputs": [],
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if USE_CUDA else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC9xHrlt4LL9"
      },
      "source": [
        "##2. Preprocess data\n",
        "- Vocab (단어장) 을 만듭니다.\n",
        "- Iterator 를 만듭니다. (Iterator 를 통해 batch training 을 위한 batching 과 padding, 그리고 데이터 내 단어들의 인덱스 변환이 이루어집니다.)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "snEZbJb4WBZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab6d8769-25fe-40eb-e082-3162010a60e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:41, 5.33MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:14<00:00, 28354.70it/s]\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained word vectors (about 7mins)\n",
        "TEXT.build_vocab(train_data, vectors = \"glove.6B.100d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1fNOoZwZurdQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28de33b7-a2d1-40d4-bc84-da0a3eec7493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vocabulary: 225481\n"
          ]
        }
      ],
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "suJRz9fgur1_"
      },
      "outputs": [],
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "# 쓸모없는 건 필요없으니까 25000개만 넣음.\n",
        "TEXT.build_vocab(train_data,\n",
        "                 max_size = MAX_VOCAB_SIZE,\n",
        "                 vectors = \"glove.6B.100d\",\n",
        "                 unk_init = torch.Tensor.normal_                 \n",
        "                 )\n",
        "LABEL.build_vocab(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ES2qQ9kdu71e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "614e6d99-a7b4-4668-bae0-0d88794955a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ]
        }
      ],
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "692haI3q1XZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "821a63ff-4680-49fc-9793-fe8e0fdab4f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', 'the', 'a', 'and', 'of', 'to', 'is', 'in', 'I']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "TEXT.vocab.itos[:10]  #itos – A list of token strings indexed by their numerical identifiers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TolmqsvNvoCD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab4f5653-2949-41ed-d0fc-c75cc6fe4c7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25002\n",
            "0 1\n",
            "THINK 25001\n"
          ]
        }
      ],
      "source": [
        "word_dict = TEXT.vocab.stoi # stoi – A collections.defaultdict instance mapping token strings to numerical identifiers.\n",
        "print(len(word_dict))\n",
        "print(word_dict['<unk>'], word_dict['<pad>'])\n",
        "print(list(word_dict)[-1], word_dict[list(word_dict)[-1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "JUCn66DV3EQS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab7425fa-7871-463f-b14e-ee7e706fe426"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([25002, 100])\n",
            "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
            "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [ 1.0003,  1.1731, -0.7108,  ...,  0.1007, -0.5921, -0.5974],\n",
            "        [-0.3989,  0.5126,  0.6494,  ...,  0.0551, -0.6197, -0.1320],\n",
            "        [-0.3997, -0.9111, -0.3559,  ...,  0.6468,  0.1014, -1.3005]])\n"
          ]
        }
      ],
      "source": [
        "print(TEXT.vocab.vectors.shape)\n",
        "print(TEXT.vocab.vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gvmmOAIPJTA5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "251150a6-7a7f-480c-ff01-377b304e08ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[   18,    49,  1925,  ..., 24625,    49,  1646],\n",
            "        [ 1901,    21,     0,  ...,   139,    21,     5],\n",
            "        [    5,   521,   160,  ...,  9606,     0, 16252],\n",
            "        ...,\n",
            "        [    1,     1,    70,  ...,     1,     1,     1],\n",
            "        [    1,     1,    12,  ...,     1,     1,     1],\n",
            "        [    1,     1,   726,  ...,     1,     1,     1]], device='cuda:0'), tensor([779, 393, 901, 756, 232, 312, 284, 130, 128, 293, 171, 213, 744, 154,\n",
            "        181, 228, 127,  79, 128, 148, 199, 114, 400, 132, 267, 341, 140, 123,\n",
            "        128, 204, 277, 328], device='cuda:0'))\n",
            "901\n",
            "tensor([0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Batching - construct iterator << 반복적 학습 시, \n",
        "BATCH_SIZE = 32   \n",
        "\n",
        "train_iterator = data.Iterator(\n",
        "    train_data, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)\n",
        "\n",
        "# shape: BATCH_SIZE x maximum length of sentence \n",
        "\n",
        "for batch in train_iterator:\n",
        "    break\n",
        "print(batch.text)\n",
        "print(len(batch.text[0]))\n",
        "print(batch.label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_uKU20YTxgaQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3300f298-b37d-4ef2-b28f-be3392c8d716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[    9,    49,  6605,  ..., 14702,   321,    49],\n",
            "        [  161,     7,  4308,  ...,    29,    33,     7],\n",
            "        [   12,     3,     4,  ...,     2,     5,   348],\n",
            "        ...,\n",
            "        [ 1344,    13,   112,  ...,     0,  5425,  1073],\n",
            "        [ 2162,  5128,    30,  ...,     1,     1,     1],\n",
            "        [ 4458,   471,     0,  ...,     1,     1,     1]], device='cuda:0'), tensor([115, 115, 115, 115, 115, 115, 114, 114, 114, 114, 114, 114, 114, 114,\n",
            "        114, 114, 114, 114, 114, 114, 113, 113, 113, 113, 113, 113, 113, 113,\n",
            "        113, 113, 113, 113], device='cuda:0'))\n",
            "115\n",
            "tensor([0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# BucketIterator\n",
        "\n",
        "train_iterator = data.BucketIterator(\n",
        "    train_data, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    device = device)\n",
        "\n",
        "for batch in train_iterator:\n",
        "    break\n",
        "print(batch.text)\n",
        "print(len(batch.text[0]))\n",
        "print(batch.label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sOD6AiIwKu-G"
      },
      "outputs": [],
      "source": [
        "# Batching - construct iterator\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_sizes = (BATCH_SIZE, BATCH_SIZE, BATCH_SIZE),\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_tAoIcUMp3v"
      },
      "source": [
        "##3. Build Model\n",
        "- Embedding layer, RNN layer, Dropout layer, Fully-connected layer 로 이루어진 모델을 만듭니다.\n",
        "- 미리 학습된 워드 임베딩을 임베딩 레이어에 올립니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "-Jdh8JGOMyYq"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):  # Custom model 정의 \n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        # Define parameters\n",
        "        # TO-DO\n",
        "        # hidden_dim, n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        # Define Layers\n",
        "        # Embedding layer\n",
        "        # TO-DO\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
        "\n",
        "        # RNN layer\n",
        "        # TO-DO\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "\n",
        "        # Fully connected layer\n",
        "        # TO-DO\n",
        "        self.fc=nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "        # Dropout layer\n",
        "        # TO-DO\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "        # [input]text = [sent len, batch size]\n",
        "        # TO-DO\n",
        "        # embedding\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        # embedded = [sent len, batch size, emb dim]\n",
        "        # embedded = [batch size, sent len, emb dim] if batch_first = True\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "\n",
        "        # TO-DO\n",
        "        # forward \n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:],hidden[-1,:,:]),dim =1))\n",
        "\n",
        "        return self.fc(hidden.squeeze(0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz7u51ACdAF1"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## (추가설명)\n",
        "### Bidirectional RNN 의 \"concatenation\" 에 대하여\n",
        "* `batch_size = 3, hidden_dim = 10, n_layers = 1, bidirectional = True` 일때 \n",
        "* RNN 모델은 forward layer 와 backward layer 총 2개 레이어를 가지게 됩니다.\n",
        "* 편의상 forward layer 의 hidden state 의 모든 unit 이 0이 되고,\n",
        "backward layer 의 경우 모두 1이 된다고 가정하겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "hWfDw4SrpPuh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8960d73-7edf-4d82-ea82-bef1706372e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "# 한개의 input 이 들어왔을때, 마지막 타임 스텝에서의 forward/backward hidden state 는 각각 다음과 같은 형태가 될 것입니다.\n",
        "h_forward = torch.zeros(1,10) \n",
        "h_backward = torch.ones(1,10)\n",
        "print(h_forward)\n",
        "print(h_backward)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-qmnArWg59T"
      },
      "source": [
        " \n",
        "\n",
        "\n",
        "*   Torch.nn 제공 RNN 모듈은 2개의 아웃풋 중 하나로 hidden state 을 출력하며,\n",
        "> `output, hidden = self.rnn(embedded)`\n",
        "*   `hidden`은 모델에 들어있는 **모든 레이어**의 last hidden state 을 출력합니다.\n",
        "*   따라서 `hidden` 의 형태는 `[num_layers x num_directions, batch_size, hidden_size]`가 됩니다.\n",
        "\n",
        "* 모델에서 총 n개의 layer 를 사용할 경우, 순서대로 _1번째 forward, 1번째 backward, 2번째 forward, 2번째 backward, ..., n번째 forward, n번째 backward_ 가 표시됩니다.\n",
        "* 이 예제에서는 `n_layers = 1`이므로 `hidden` 의 shape 은 `[2,3,10]` 이 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "h1WG9R_AD5j5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a1481e-ea68-4159-c3b1-93f4f1c95f9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]])\n",
            "torch.Size([2, 3, 10])\n"
          ]
        }
      ],
      "source": [
        "# hidden 은 아래와 같이 생기게 됩니다.\n",
        "hidden = torch.cat([h_forward.unsqueeze(0).repeat([1,3,1]),h_backward.unsqueeze(0).repeat([1,3,1])])\n",
        "\n",
        "print(hidden)\n",
        "print(hidden.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8l5cPHpk4k0"
      },
      "source": [
        "\n",
        "*   우리는 forward 와 backward layer 각각에서 나온 last hidden state를 나란히 합치고자 합니다.\n",
        "*  `hidden[-2,:,:]` 는 forward layer 의 last hidden state 을 나타내고\n",
        "*  `hidden[-1,:,:]` 는 backward layer 의 last hidden state 을 나타냅니다.\n",
        "* 이 두개를 hidden_size 를 나타내는 dimension=1 의 방향으로 concatenate 합니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "j4zx6Cj_bNoC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35999c13-74c3-42bb-9026-8605ed465cdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1.]])\n",
            "torch.Size([3, 20])\n"
          ]
        }
      ],
      "source": [
        "# 최종적으로 사용하는 Bidirectional RNN 모델의 아웃풋은 다음과 같은 형태를 가집니다.\n",
        "h_concat = torch.cat([hidden[-2,:,:],hidden[-1,:,:]],dim=1)\n",
        "print(h_concat)\n",
        "print(h_concat.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrXn7s7dtDd8"
      },
      "source": [
        "## (추가설명 종료)\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "n4EffzRaafEY"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = Model(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)    # Make model instance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "gCUKXn94afEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77b17857-3734-4a17-9f17-478c712ff688"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 4,810,857 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)  # Count number of elements of all parameters\n",
        "\n",
        "print('The model has {:,} trainable parameters'.format(count_parameters(model)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "vgZ8wIYlG-_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb434427-0285-456e-c4aa-541176dfabce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "# load pretrained embeddings\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "print(type(pretrained_embeddings))\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDy-PGhSQcTd"
      },
      "source": [
        "## 4. Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "09bHscfRG9ju"
      },
      "outputs": [],
      "source": [
        "# TO-DO\n",
        "# optimizer : Adam\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "YeZZ33ZeafEt"
      },
      "outputs": [],
      "source": [
        "# TO-DO\n",
        "# criterion : Binarcy Cross Entropy with Logit Loss\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "3bOa8C1tafEz"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)  #모델을 GPU 로 이동\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "7exIxGaZafE4"
      },
      "outputs": [],
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "1Eb16jU0afFA"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # TO-DO\n",
        "        # General Training Scheme\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        prediction = model(batch.text[0]).squeeze(1)\n",
        "        loss = criterion(prediction, batch.label)\n",
        "        acc = binary_accuracy(prediction, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "8da_fbPRQ9I3"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "            # TO-DO\n",
        "            # General Evaluation Scheme\n",
        "            \n",
        "            predicitons = model(batch.text[0]).squeeze(1)\n",
        "            eval_loss = criterion(model(batch.text[0]).squeeze(1), batch.label)\n",
        "            eval_acc = binary_accuracy(model(batch.text[0]).squeeze(1), batch.label)\n",
        "\n",
        "            \n",
        "            epoch_loss += eval_loss.item()\n",
        "            epoch_acc += eval_acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#오류로 criterion(predictions, batch.label) 에 predictions 대신 model(batch.text[0]).squeeze(1)로 했습니다."
      ],
      "metadata": {
        "id": "k0M9LbKX1Vln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZhS9Q2fSLyr"
      },
      "source": [
        "### *Do Training!*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "2uUWlVrUQ-lz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7526889-d0fa-481a-b2ea-c5a4c0cebd78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01\n",
            "\tTrain Loss: 0.163 | Train Acc: 94.50%\n",
            "\t Val. Loss: 0.357 |  Val. Acc: 86.08%\n",
            "Epoch: 02\n",
            "\tTrain Loss: 0.114 | Train Acc: 96.40%\n",
            "\t Val. Loss: 0.430 |  Val. Acc: 86.41%\n",
            "Epoch: 03\n",
            "\tTrain Loss: 0.074 | Train Acc: 97.98%\n",
            "\t Val. Loss: 0.497 |  Val. Acc: 86.16%\n",
            "Epoch: 04\n",
            "\tTrain Loss: 0.051 | Train Acc: 98.76%\n",
            "\t Val. Loss: 0.541 |  Val. Acc: 85.96%\n",
            "Epoch: 05\n",
            "\tTrain Loss: 0.038 | Train Acc: 99.11%\n",
            "\t Val. Loss: 0.627 |  Val. Acc: 85.08%\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 5  # about 13 mins\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'rnn-model.pt')\n",
        "        #나은 성능이면 저장\n",
        "    \n",
        "    print('Epoch: {:02}'.format(epoch+1))\n",
        "    print('\\tTrain Loss: {:.3f} | Train Acc: {:.2f}%'.format(train_loss, train_acc*100))\n",
        "    print('\\t Val. Loss: {:.3f} |  Val. Acc: {:.2f}%'.format(valid_loss, valid_acc*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "3mXZ46wgRHWR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65938a97-d1e5-439b-b6de-3ebd208f031c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.394 | Test Acc: 84.18%\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('rnn-model.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print('Test Loss: {:.3f} | Test Acc: {:.2f}%'.format(test_loss, test_acc*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EtTQaIdafFL"
      },
      "source": [
        "## 5. Test model\n",
        "우리가 직접 예문을 작성해서 트레인된 모델에서 예문을 어떻게 평가하는지 확인합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "_hxev65tafFQ"
      },
      "outputs": [],
      "source": [
        "# 토크나이저로 spacy 를 사용합니다.\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# 사용자가 입력한 sentence 를 훈련된 모델에 넣었을때의 결과값을 확인합니다.\n",
        "def predict_sentiment(model, sentence):\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]  # Tokenization\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]   # 위에서 만든 vocab 에 부여된 index 로 indexing\n",
        "    tensor = torch.LongTensor(indexed).to(device)   # indexing 된 sequence 를 torch tensor 형태로 만들어줌.\n",
        "    tensor = tensor.unsqueeze(1)   # 입력 텐서에 batch 차원을 만들어줌.\n",
        "    prediction = torch.sigmoid(model(tensor))  # 모델에 입력한 후 확률값 도출을 위한 sigmoid 적용 \n",
        "    return prediction.item() # prediction 값 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "dIk_EjmoSFdU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa449f28-c983-4035-8ce8-02e81699d200"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.011125648394227028"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "predict_sentiment(model, \"This film is terrible\") #아주 낮은 값의 확률이 도출되는 것을 확인할 수 있습니다.(부정)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "A1ZZJbxaSFaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75beb515-320f-4bec-f04e-a4524ef10380"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9912176132202148"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "predict_sentiment(model, \"This film is great\") #아주 높은 값의 확률이 도출되는 것을 확인할 수 있습니다. (긍정)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDjerqMQRx9u"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "PyTorch 1.0.0-3.6",
      "language": "python",
      "name": "multitask"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}