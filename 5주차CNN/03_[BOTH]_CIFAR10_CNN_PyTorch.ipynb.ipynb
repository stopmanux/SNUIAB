{"cells":[{"cell_type":"markdown","metadata":{"id":"HN4Z8nIbI_Vz"},"source":["# PyTorch를 이용해서 CIFAR 10 이미지 분류 해보기"]},{"cell_type":"markdown","metadata":{"id":"K9CGMBW-I_V4"},"source":["# 딥러닝 모델을 학습시키기 위해 준비되어야 할 4가지 요소\n","\n","1. 데이터\n","2. 모델\n","3. Loss function (손실함수, 목적함수, objective function 등으로 불려요): 정답과 모델의 예측값을 어떤 식으로 비교할지 결정해주는 함수\n","4. Optimizer: gradient descent를 해줄 애. 즉, 모델의 파라미터를 어느 방향으로 조금 수정할지 결정하고 수정해주는 함수"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uFsW7S9jI_V5"},"outputs":[],"source":["%matplotlib inline\n","\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms"]},{"cell_type":"markdown","metadata":{"id":"KgmzdGfFI_V7"},"source":["## 모델에 데이터 넣을 준비하기\n","\n","우선 사용하고 싶은 데이터 파일이 있다면 그걸 우선 numpy array 형식으로 불러와야 해요<br/>\n","그리고는 필요한 전처리를 해준 후에 이 numpy array를 `torch.*Tensor` 형식으로 변환하고 <br/>\n","dataloader에 넣어주면 pytorch로 짠 딥러닝 모델에 넣을 준비가 된 것입니다.<br/>\n","\n","대개 이제 이런 데이터 처리를 도와주는 패키지들이 있는데<br/>\n","이미지는 openCV, Pillow를 많이 쓰고,<br/>\n","텍스트에는 SpaCy를 많이 사용해요. <br/>\n","\n","그런데 pytorch에서 고맙게도 그 데이터를 불러오고 전처리를 하는 걸<br/>\n","파이토치와 매끄럽게 잘 이어지도록 도와주는 패키지를 만들었놨어요.<br/>\n","* [torchvision](https://pytorch.org/docs/stable/torchvision/index.html#)\n","* [torchtext](https://torchtext.readthedocs.io/en/latest/)\n","\n","몇몇 대표 데이터셋들은 해당 패키지에 이미 들어있어서<br/>\n","그냥 가져다 불러와서 쓰고 몇몇 처리만 해주면 사용할 준비가 끝나요!\n","\n","이번에는 CIFAR 10이라는 데이터셋을 사용합니다.<br/>\n","이는 대표적인 데이터셋 중 하나라서 기억해두시면 이따금씩 보일 거예요.<br/>\n","클래스가 10개라서 CIFAR 10입니다.<br/>\n","\n","들어있는 클래스는<br/>\n","‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’ 입니다.<br/>\n","size는 3x32x32이고 앞의 3은 RGB여서 그런 거예요.<br/>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J3moKeFTI_V8"},"outputs":[],"source":["transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","# 이미지는 RGB  3가지의 채널로 이루어져있으므로, 각 채널에 대한 mean, std를 넣어줘서 normalize해줘야 해요\n","# 이미지 데이터의 값이 0~1 사이였는데 이를 통해 -1 ~ +1 사이로 변환해줍니다.\n","\n","batchsize = 16\n","\n","# 너무나 간단합니다. torchvision에 이미 다 알아서 처리가 되어있어서 이렇게 편하게 불러올 수 있는 거예요!\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchsize,\n","                                          shuffle=True, num_workers=2)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batchsize,\n","                                         shuffle=False, num_workers=2)\n","\n","# 이런 클래스들이 데이터셋 안에 있습니다.\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"]},{"cell_type":"markdown","metadata":{"id":"K0i3SvVXI_V8"},"source":["## 학습 이미지 예시 보기\n","\n","32x32짜리 이미지라서 화질이 안 좋은 건 자연스러운 일입니다... <br/>\n","놀랍게도 이런 이미지들로 학습을 합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3-DI7OwOI_V9"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# functions to show an image\n","def imshow(img):\n","    img = img / 2 + 0.5     # 아까 앞에서 normalize해줘서 색깔 이미지가 이상해져있을 거기 때문에 보기 편하라고 다시 unnormalize해줍니다\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","# get some random training images\n","dataiter = iter(trainloader)\n","#images, labels = dataiter.next()\n","images, labels = next(dataiter)\n","\n","# show images\n","imshow(torchvision.utils.make_grid(images))\n","# print labels\n","print( '정답:' + '  \\t\\t '.join('%5s' % classes[labels[j]] for j in range(4)))"]},{"cell_type":"markdown","metadata":{"id":"33nlLL3vI_V-"},"source":["## 모델 정의하기\n","\n","앞선  notMNIST는 흑백 이미지라서 채널이 1개였지만 <br/>\n","여기서는 컬러 이미지라서 채널이 3개라는 거에 유의합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sku-EzAUI_V-"},"outputs":[],"source":["import torch.nn as nn\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","\n","        ############### fc layer를 완성해보세요 ################\n","        \n","        #self.fc1 = nn.Linear(인풋 숫자 , 아웃풋 숫자 )\n","\n","        ########################################################\n","\n","    def forward(self, x):\n","        # x = self.conv1(x)\n","        # x = self.relu(x)\n","        # x = self.pool(x)\n","        \n","        # 위를 압축해서 쓴 게 아래 줄이에요!\n","        x = self.pool(self.relu(self.conv1(x)))\n","        \n","        ############### 빈칸을 완성 해보세요 ################\n","\n","        #x = x.view(-1, 여긴 뭐가 들어가야 할까요)  # 얘의 기능은 텐서의 모양을 원하는 모양으로 바꿔주는 거예요\n","        # 그냥 예시: x가 만약 (16, 3, 12, 12) 모양이었다면 x.view(-1, 144)는 (48, 144) 모양으로 바꿔준답니다. -1은 나머지 숫자를 자동으로 채워주는 역할이에요\n","        \n","        ########################################################\n","\n","        return x\n","\n","\n","net = Net()"]},{"cell_type":"markdown","metadata":{"id":"CgNsbKnlI_V_"},"source":["## Loss function과 Optimizer 정의하기\n","\n","Cross-entropy loss function과 SGD optimizer를 씁니다.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hrmaVytMI_V_"},"outputs":[],"source":["import torch.optim as optim\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)  # Learning rate: 학습률. 한 번의 optimizer step에서 얼마나 멀리 갈지. "]},{"cell_type":"markdown","metadata":{"id":"68jYQZ-AI_WA"},"source":["## 모델 학습시키기\n","\n","이제\n","* data loader\n","* model\n","* loss function\n","* optimizer\n","\n","이 4가지가 모두 준비되었으니 학습을 할 준비가 끝났습니다.\n","\n","```\n","종료 조건 만족할 때까지 아래를 반복:\n","    1. 우리의 data loader로부터 데이터를 받아와서 모델에 넣어주고\n","    2. 모델의 출력 값을 받아서 \n","    3. loss function 값을 계산하고\n","    4. 그 loss를 바탕으로 backprop(=gradient를 계산) 해준 뒤 \n","    5. optimizer가 gradient descent를 1 step 진행합니다.\n","    ```"]},{"cell_type":"markdown","metadata":{"id":"t3coKO5lI_WA"},"source":["### 근데...\n","\n","학습을 하면서 테스트셋 성적이 어떻게 변하는지를 보는 건 어때요?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67q-pRJpI_WA"},"outputs":[],"source":["training_loss_history = []\n","test_loss_history = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nO9Hejp1I_WB"},"outputs":[],"source":["for epoch in range(2):  # 전체 데이터셋을 몇 번 반복할 건지\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        # trainloader로부터 데이터와 라벨을 받아옵니다.\n","        inputs, labels = data\n","\n","        # 매 반복마다 이전 gradient를 한 번 지워줍니다.\n","        optimizer.zero_grad()\n","\n","        # 모델에 데이터 넣어서 forward 해주고 \n","        # backprop으로 이번 input에 대해 gradient를 계산해주고\n","        # optimizer가 gradient descent 1스텝 진행\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # 결과치 화면에 뿌려주기\n","        running_loss += loss.item()\n","        if i % 200 == 199:    # 2000 미니배치마다 출력\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 200))\n","\n","            # 나중에 시각화를 위해 중간중간 따로 loss값 저장\n","            training_loss_history.append(running_loss / 200)\n","            \n","            with torch.no_grad():\n","                running_test_loss = 0.0\n","                for i, test_data in enumerate(testloader, 0):\n","                    test_images, test_labels = test_data\n","                    test_outputs = net(test_images)\n","                    test_loss = criterion(test_outputs, test_labels)\n","                    running_test_loss += test_loss.item()\n","                \n","                test_loss_history.append(running_test_loss / i)\n","                    \n","            running_loss = 0.0\n","                    \n","print('학습 끝!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aKK43yjvI_WB"},"outputs":[],"source":["plt.plot(training_loss_history) \n","plt.title('Training Loss', fontsize=20)  # 여기에 한글을 넣고 싶으시다구요? 그럼 좀 귀찮은 몇 가지 작업들을 해야 합니다... 그러므로 패스\n","plt.xlabel('Iteration',fontsize=16)\n","plt.ylabel('Loss',fontsize=16)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"2jEmetJ2I_WC"},"source":["[그래도 난 matplotlib에 한글을 넣겠어!](https://programmers.co.kr/learn/courses/21/lessons/950)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JPYoOMHnI_WD"},"outputs":[],"source":["plt.plot(training_loss_history, label=\"Training Loss\") \n","plt.plot(test_loss_history, 'r', label=\"Test Loss\") \n","plt.title('Training & Test Loss', fontsize=20) \n","plt.xlabel('Iteration',fontsize=16)\n","plt.ylabel('Loss',fontsize=16)\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"4hum5q1OI_WD"},"source":["## 모델 저장하기\n","\n","학습이 끝난 모델의 파라미터를 저장해두면 나중에 필요할 때 불러와서 가져다 쓰면 바로 사용할 수 있어요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pJoY_1zAI_WD"},"outputs":[],"source":["PATH = './cifar_net.pth'\n","torch.save(net.state_dict(), PATH)"]},{"cell_type":"markdown","metadata":{"id":"BOpJUixZI_WE"},"source":["## 테스트셋에 검증해보기\n","\n","이제 모델 학습이 끝났으니 테스트 데이터에도 잘하는지 확인을 해봐야 합니다. <br/>\n","테스트셋 데이터 중 몇 개나 맞히는지 알아볼까요?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Iq6J0VbmI_WE"},"outputs":[],"source":["# 테스트셋 이미지 예시도 심심풀이로 한 번 확인해보기\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batchsize,\n","                                         shuffle=False, num_workers=2)\n","dataiter = iter(testloader)\n","images, labels = dataiter.next()\n","\n","imshow(torchvision.utils.make_grid(images))"]},{"cell_type":"markdown","metadata":{"id":"BIv6dNsoI_WE"},"source":["### 아까 저장해뒀던 모델 파라미터 불러오기\n","\n","사실 굳이 불러오지 않고 그냥 위에 있는 `net` 그대로 써도 되지만 <br/>\n","일단 어떻게 저장하고 불러오는지 여러분이 알아둬야 하니까 여기서는 `net`에 굳이 다시 불러와봤어요"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1coBwqxzI_WF"},"outputs":[],"source":["net = Net()\n","net.load_state_dict(torch.load(PATH))"]},{"cell_type":"markdown","metadata":{"id":"XTCH727CI_WF"},"source":["이미지들을 넣었을 때 모델이 뭐라고 예측하는지 한 번 확인해볼게요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j6V6Dq1WI_WF"},"outputs":[],"source":["outputs = net(images)\n","outputs"]},{"cell_type":"markdown","metadata":{"id":"k-kCIiN7I_WF"},"source":["뭔지 전혀 모르겠죠? <br/>\n","각 row에 있는 숫자들은 10개의 클래스에 대한 logit 값이에요. (확률 값이 아니라) <br/>\n","어떤 인덱스의 logit값이 크면 모델은 그 해당 인덱스의 클래스로 해당 이미지를 분류한다는 의미입니다. <br/>\n","따라서 그냥 이 logit 값들 중 제일 큰 logit이 있는 index를 각 row마다 뽑아오면 됩니다. <br/>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ptWI7USI_WF"},"outputs":[],"source":["_, predicted = torch.max(outputs, 1)  # 1번째 차원(=각 row)에서 각각 max인 값과 해당 index를 뽑아옵니다.\n","\n","print('모델 예측: ', ', '.join('%5s' % classes[predicted[j]]\n","                              for j in range(4)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JmB7ZsuBI_WG"},"outputs":[],"source":["# 원래 이미지랑 같이 볼까요?\n","imshow(torchvision.utils.make_grid(images[:4]))\n","print('실제 정답: ', ', '.join('%5s' % classes[labels[j]] for j in range(4)))\n","print('모델 예측: ', ', '.join('%5s' % classes[predicted[j]]\n","                              for j in range(4)))"]},{"cell_type":"markdown","metadata":{"id":"NJskbHisI_WG"},"source":["나름 잘 맞히는 거 같습니다. <br/>\n","그러면 이제 전체 테스트셋에 대해 정답과 비교해서 몇 개나 맞히는지 보겠습니다. \n","\n","### 테스트셋 정답률 확인해보기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kMyd4pIiI_WG"},"outputs":[],"source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('10000개의 테스트 이미지에 대한 정답률: %d %%' % (\n","    100 * correct / total))"]},{"cell_type":"markdown","metadata":{"id":"YPRTKV-kI_WG"},"source":["### 각 클래스 별 정답률 확인해보기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EJsxcMIJI_WH"},"outputs":[],"source":["class_correct = list(0. for i in range(10))\n","class_total = list(0. for i in range(10))\n","\n","with torch.no_grad():  # 매우매우 중요! 테스트셋으로 학습하는 건 반칙입니다. 테스트셋으로 backprop을 하면 안 되지요.\n","    for data in testloader:\n","        images, labels = data\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs, 1)\n","        c = (predicted == labels).squeeze()\n","        for i in range(4):\n","            label = labels[i]\n","            class_correct[label] += c[i].item()\n","            class_total[label] += 1\n","\n","\n","for i in range(10):\n","    print('%5s 클래스의 정답률 : %2d %%' % (\n","        classes[i], 100 * class_correct[i] / class_total[i]))"]},{"cell_type":"markdown","metadata":{"id":"XI7iPfzGI_WH"},"source":["# 과제:\n","\n","### 1.ipynb 파일 제출 (10점)\n","convolution layer **2층** 이상의 convnet을 만들어서 <br/>\n","테스트 데이터에 대한 정답률을 높여서 ipynb 파일을 제출을 하시면 됩니다! <br/>\n","모델을 정의하고 이것저것 바꿔보세요. <br/>\n","**55%**를 넘겨보도록 해보세요!\n","\n","- 55%를 넘기시면 8점\n","- 57.5%를 넘기시면 9점\n","- 60%를 넘기시면 10점\n","\n","수업 시간에 말한 거 이외의 힌트:<br/>\n","`self.conv2`가 있어야겠죠 2층을 쌓으려면? <br/>\n","이건 weight기 때문에 따로 별도로 `self.conv2`가 있어야 하지만 relu나 maxpool은 파라미터가 없기 때문에 있는 거 그대로 쓰시면 되는 거예요! <br/>\n","과제에서 반드시 convolution layer를 2층 이상을 쌓으셔야 해요. 거기에 추가로 fc layer도 더 쌓으실 수도 있겠죠? <br/>\n","\n","### 2.실험 결과 설명 제출 (5점)\n","Learning rate를 크게 해서 돌려보기도 하고 작게 해서 돌려보기도 하면서 각각의 training loss graph를 비교해보세요.<br/>\n","앞에서 한 것처럼 그래프를 그려보세요. 각 실험에 대한 graph가 노트북 파일 내에 남아있어야 해요. <br/>\n","그리고 그 성능에 차이가 나는 이유를 생각해서 써보세요. \n","\n","## 주의사항\n","ipynb 파일의 이름은 `[학번]_[이름].ipynb`로 제출하셔야 합니다. 예시: `2019-12321_김학생.ipynb`<br/>\n","형식을 지키지 않으실 경우 감점 1점 있습니다."]},{"cell_type":"markdown","metadata":{"id":"nAfYyjXKI_WH"},"source":["## 실험 결과 설명 작성하는 칸\n","\n","여기에 작성하세요"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XOtpr6AaI_WH"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HP87bfzNI_WI"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZqL5hZiyI_WI"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"DdSRpZjnI_WI"},"source":["## [덧] GPU 위에서 학습하기\n","\n","지금까지는 cpu위에서 다 계산을 한 거예요.<br/>\n","GPU 위에서 저희 모델이 인풋 데이터를 받아서 출력을 계산하고 싶잖아요? <br/>\n","그러면 해야 할 일은<br/>\n","모델도 gpu에 보내고, 데이터도 gpu에 보내는 일입니다.<br/>\n","\n","그러기 위해선 일단 gpu가 사용 가능한지부터 봐야겠죠?<br/>\n","CUDA available:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2IbSU7W4I_WI"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# CUDA가 있는 컴퓨터라면 CUDA 라고 뜨고 아니면 cpu라고 뜰 겁니다\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"w-0eaYPII_WI"},"source":["The rest of this section assumes that ``device`` is a CUDA device.\n","\n","Then these methods will recursively go over all modules and convert their\n","parameters and buffers to CUDA tensors:\n","\n","아래처럼 수정을 해주면 모델이 gpu 위에 올라갑니다\n","\n","```python\n","net = net.to(device)\n","```\n","\n","데이터도 올려줘야겠죠?\n","\n","```python\n","inputs, labels = data[0].to(device), data[1].to(device)\n"," ```\n","\n","지금은 모델이 너무 작아서 gpu에서 하든 cpu에서 하든 속도 차이가 별로 없습니다."]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/1207koo/deep_iab/blob/master/03_%5BBOTH%5D_CIFAR10_CNN_PyTorch.ipynb","timestamp":1680156654966}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":0}
